{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02B - Neuro-Symbolic Compiler: Secondary Integration Notebook\n",
    "\n",
    "This secondary notebook extends `02_neuro_symbolic_compiler.ipynb` with:\n",
    "1. 1000x1000 scale matrix benchmarking\n",
    "2. Grad-Shafranov (GS) equilibrium integration\n",
    "3. End-to-end toy control-path latency (diagnostics -> physics -> compiler -> actuator)\n",
    "4. Explicit deployment-scope boundaries\n",
    "\n",
    "**Copyright clarity**\n",
    "- Concepts: Copyright 1996-2026 Miroslav Sotek\n",
    "- Code: Copyright 2024-2026 SCPN Fusion Core contributors\n",
    "- License: GNU AGPL v3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/anulum/scpn-fusion-core/blob/main/examples/02_neuro_symbolic_compiler_secondary.ipynb)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/anulum/scpn-fusion-core/main?labpath=examples%2F02_neuro_symbolic_compiler_secondary.ipynb)\n",
    "\n",
    "---\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scpn_fusion.scpn import StochasticPetriNet, FusionCompiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define a Plasma Control Petri Net\n",
    "\n",
    "We model a simplified tokamak position controller with:\n",
    "- 4 input places (sensor observations: R_high, R_low, Z_high, Z_low)\n",
    "- 4 transitions (decision logic)\n",
    "- 4 output places (actuator commands: PF_up, PF_down, PF_in, PF_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = StochasticPetriNet()\n",
    "\n",
    "# Input places (sensor observations)\n",
    "net.add_place(\"R_high\", initial_tokens=0.0)\n",
    "net.add_place(\"R_low\",  initial_tokens=0.0)\n",
    "net.add_place(\"Z_high\", initial_tokens=0.0)\n",
    "net.add_place(\"Z_low\",  initial_tokens=0.0)\n",
    "\n",
    "# Output places (actuator commands)\n",
    "net.add_place(\"PF_up\",   initial_tokens=0.0)\n",
    "net.add_place(\"PF_down\", initial_tokens=0.0)\n",
    "net.add_place(\"PF_in\",   initial_tokens=0.0)\n",
    "net.add_place(\"PF_out\",  initial_tokens=0.0)\n",
    "\n",
    "# Transitions (control logic)\n",
    "net.add_transition(\"T_correct_R_high\", threshold=0.5)\n",
    "net.add_transition(\"T_correct_R_low\",  threshold=0.5)\n",
    "net.add_transition(\"T_correct_Z_high\", threshold=0.5)\n",
    "net.add_transition(\"T_correct_Z_low\",  threshold=0.5)\n",
    "\n",
    "# Arcs: if R is too high → move plasma inward\n",
    "net.add_arc(\"R_high\", \"T_correct_R_high\", weight=1.0)\n",
    "net.add_arc(\"T_correct_R_high\", \"PF_in\", weight=1.0)\n",
    "\n",
    "# If R is too low → move plasma outward\n",
    "net.add_arc(\"R_low\", \"T_correct_R_low\", weight=1.0)\n",
    "net.add_arc(\"T_correct_R_low\", \"PF_out\", weight=1.0)\n",
    "\n",
    "# If Z is too high → push plasma down\n",
    "net.add_arc(\"Z_high\", \"T_correct_Z_high\", weight=1.0)\n",
    "net.add_arc(\"T_correct_Z_high\", \"PF_down\", weight=1.0)\n",
    "\n",
    "# If Z is too low → push plasma up\n",
    "net.add_arc(\"Z_low\", \"T_correct_Z_low\", weight=1.0)\n",
    "net.add_arc(\"T_correct_Z_low\", \"PF_up\", weight=1.0)\n",
    "\n",
    "net.compile()\n",
    "print(net.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compile to Stochastic Neural Network\n",
    "\n",
    "The compiler maps each transition to a stochastic LIF neuron.\n",
    "If `sc-neurocore` is installed, it uses hardware-accurate bitstream\n",
    "encoding. Otherwise, it falls back to NumPy float computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler = FusionCompiler(bitstream_length=1024, seed=42)\n",
    "compiled = compiler.compile(net)\n",
    "\n",
    "print(f\"Places:      {compiled.n_places}\")\n",
    "print(f\"Transitions: {compiled.n_transitions}\")\n",
    "print(f\"Stochastic:  {compiled.has_stochastic_path}\")\n",
    "print(f\"Firing mode: {compiled.firing_mode}\")\n",
    "print()\n",
    "print(compiled.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Inference\n",
    "\n",
    "We simulate a scenario where the plasma is displaced to R_high and Z_low.\n",
    "The compiled network should activate PF_in (radial correction) and\n",
    "PF_up (vertical correction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject observation: plasma displaced R_high + Z_low\n",
    "marking = np.zeros(compiled.n_places)\n",
    "marking[0] = 0.8  # R_high active\n",
    "marking[3] = 0.9  # Z_low active\n",
    "\n",
    "W_in = compiled.W_in.toarray()\n",
    "W_out = compiled.W_out.toarray()\n",
    "\n",
    "print(\"Initial marking:\", dict(zip(net.place_names, marking)))\n",
    "\n",
    "# Step: compute transition firing\n",
    "currents = W_in @ marking\n",
    "fired = (currents >= compiled.thresholds).astype(float)\n",
    "consumed = W_in.T @ fired\n",
    "produced = W_out @ fired\n",
    "new_marking = np.clip(marking - consumed + produced, 0.0, 1.0)\n",
    "\n",
    "print(\"\\nFired transitions:\", dict(zip(net.transition_names, fired)))\n",
    "print(\"\\nNew marking:\", dict(zip(net.place_names, new_marking)))\n",
    "print(\"\\n→ PF_in activated:\", new_marking[6] > 0)   # PF_in\n",
    "print(\"→ PF_up activated:\", new_marking[4] > 0)   # PF_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Multi-Step Evolution\n",
    "\n",
    "Run the network for 30 steps with a time-varying disturbance signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 30\n",
    "history = np.zeros((n_steps + 1, compiled.n_places))\n",
    "marking = np.zeros(compiled.n_places)\n",
    "history[0] = marking\n",
    "\n",
    "for k in range(n_steps):\n",
    "    # Time-varying disturbance\n",
    "    t = k / n_steps\n",
    "    marking[0] = 0.6 * np.sin(2 * np.pi * t) ** 2   # R_high oscillation\n",
    "    marking[3] = 0.5 * np.cos(2 * np.pi * t) ** 2   # Z_low oscillation\n",
    "    \n",
    "    currents = W_in @ marking\n",
    "    fired = (currents >= compiled.thresholds).astype(float)\n",
    "    consumed = W_in.T @ fired\n",
    "    produced = W_out @ fired\n",
    "    marking = np.clip(marking - consumed + produced, 0.0, 1.0)\n",
    "    history[k + 1] = marking\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "for i in range(4):\n",
    "    axes[0].plot(history[:, i], label=net.place_names[i])\n",
    "axes[0].set_ylabel(\"Input Places\")\n",
    "axes[0].legend(loc=\"upper right\")\n",
    "axes[0].set_title(\"Petri Net Token Evolution (30 steps)\")\n",
    "\n",
    "for i in range(4, 8):\n",
    "    axes[1].plot(history[:, i], label=net.place_names[i])\n",
    "axes[1].set_ylabel(\"Output Places\")\n",
    "axes[1].set_xlabel(\"Step\")\n",
    "axes[1].legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Artifact Export / Import\n",
    "\n",
    "The compiled network can be serialised as a JSON artifact for\n",
    "deployment on embedded hardware or real-time controllers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, os\n",
    "from scpn_fusion.scpn import load_artifact, save_artifact\n",
    "\n",
    "# Export\n",
    "artifact = compiled.export_artifact(\n",
    "    name=\"position_controller_v1\",\n",
    "    dt_control_s=0.001,\n",
    "    readout_config={\n",
    "        \"action_specs\": [\n",
    "            {\"place_idx\": 4, \"label\": \"PF_up\"},\n",
    "            {\"place_idx\": 5, \"label\": \"PF_down\"},\n",
    "            {\"place_idx\": 6, \"label\": \"PF_in\"},\n",
    "            {\"place_idx\": 7, \"label\": \"PF_out\"},\n",
    "        ],\n",
    "        \"gains\": [1000.0, 1000.0, 500.0, 500.0],\n",
    "        \"abs_max\": [5000.0, 5000.0, 3000.0, 3000.0],\n",
    "        \"slew_per_s\": [1e5, 1e5, 5e4, 5e4],\n",
    "    },\n",
    "    injection_config=[\n",
    "        {\"place_idx\": 0, \"label\": \"R_high\"},\n",
    "        {\"place_idx\": 1, \"label\": \"R_low\"},\n",
    "        {\"place_idx\": 2, \"label\": \"Z_high\"},\n",
    "        {\"place_idx\": 3, \"label\": \"Z_low\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "fd, path = tempfile.mkstemp(suffix=\".scpnctl.json\")\n",
    "os.close(fd)\n",
    "save_artifact(artifact, path)\n",
    "print(f\"Saved artifact to: {path}\")\n",
    "print(f\"File size: {os.path.getsize(path)} bytes\")\n",
    "\n",
    "# Reload\n",
    "loaded = load_artifact(path)\n",
    "print(f\"\\nReloaded: {loaded.meta['name']}\")\n",
    "print(f\"Places: {loaded.nP}, Transitions: {loaded.nT}\")\n",
    "os.unlink(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Performance Benchmarks\n\nTiming the key computations in this notebook:\n1. **Petri net compilation** (`FusionCompiler.compile`)\n2. **Single inference step** (matrix multiply + threshold)\n3. **30-step evolution loop** (multi-step token propagation)\n4. **Artifact export/import round-trip**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import timeit\n\n# 1. Petri net compilation\ndef bench_compile():\n    c = FusionCompiler(bitstream_length=1024, seed=42)\n    c.compile(net)\n\nt_compile = timeit.repeat(bench_compile, number=10, repeat=5)\nprint(f\"FusionCompiler.compile (10 calls):\")\nprint(f\"  Mean: {np.mean(t_compile)*1000:.1f} ms +/- {np.std(t_compile)*1000:.1f} ms\")\nprint(f\"  Per call: {np.mean(t_compile)/10*1000:.2f} ms\")\n\n# 2. Single inference step (matrix multiply + threshold)\nW_in_dense = compiled.W_in.toarray()\nW_out_dense = compiled.W_out.toarray()\ntest_marking = np.zeros(compiled.n_places)\ntest_marking[0] = 0.8\ntest_marking[3] = 0.9\n\ndef bench_single_step():\n    currents = W_in_dense @ test_marking\n    fired = (currents >= compiled.thresholds).astype(float)\n    consumed = W_in_dense.T @ fired\n    produced = W_out_dense @ fired\n    np.clip(test_marking - consumed + produced, 0.0, 1.0)\n\nt_step = timeit.repeat(bench_single_step, number=10000, repeat=5)\nprint(f\"\\nSingle inference step (10000 calls):\")\nprint(f\"  Mean: {np.mean(t_step)*1000:.1f} ms +/- {np.std(t_step)*1000:.1f} ms\")\nprint(f\"  Per call: {np.mean(t_step)/10000*1e6:.2f} us\")\n\n# 3. 30-step evolution loop\ndef bench_evolution():\n    m = np.zeros(compiled.n_places)\n    for k in range(30):\n        t = k / 30\n        m[0] = 0.6 * np.sin(2 * np.pi * t) ** 2\n        m[3] = 0.5 * np.cos(2 * np.pi * t) ** 2\n        currents = W_in_dense @ m\n        fired = (currents >= compiled.thresholds).astype(float)\n        consumed = W_in_dense.T @ fired\n        produced = W_out_dense @ fired\n        m = np.clip(m - consumed + produced, 0.0, 1.0)\n\nt_evo = timeit.repeat(bench_evolution, number=100, repeat=5)\nprint(f\"\\n30-step evolution (100 runs):\")\nprint(f\"  Mean: {np.mean(t_evo)*1000:.1f} ms +/- {np.std(t_evo)*1000:.1f} ms\")\nprint(f\"  Per run: {np.mean(t_evo)/100*1000:.2f} ms\")\n\n# 4. Artifact export round-trip\nimport tempfile, os\n\ndef bench_export_import():\n    art = compiled.export_artifact(\n        name=\"bench_test\", dt_control_s=0.001,\n        readout_config={\"action_specs\": [], \"gains\": [], \"abs_max\": [], \"slew_per_s\": []},\n        injection_config=[],\n    )\n    fd, p = tempfile.mkstemp(suffix=\".scpnctl.json\")\n    os.close(fd)\n    save_artifact(art, p)\n    load_artifact(p)\n    os.unlink(p)\n\nt_io = timeit.repeat(bench_export_import, number=10, repeat=3)\nprint(f\"\\nArtifact export/import round-trip (10 calls):\")\nprint(f\"  Mean: {np.mean(t_io)*1000:.1f} ms +/- {np.std(t_io)*1000:.1f} ms\")\nprint(f\"  Per call: {np.mean(t_io)/10*1000:.2f} ms\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Baseline notebook flow is preserved above. The sections below add:\n",
    "1. Scale benchmark at 1000x1000 matrix size\n",
    "2. GS solver output coupling to diagnostic-derived controller inputs\n",
    "3. Full toy-chain latency, not only neural net forward time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 1000x1000 Scale Benchmark\n",
    "\n",
    "This benchmark reports dense 1000x1000 matrix performance for control-style linear algebra.\n",
    "Results are hardware-dependent and should be interpreted as local-machine measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rng_scale = np.random.default_rng(7)\n",
    "N = 1000\n",
    "W_scale = rng_scale.standard_normal((N, N), dtype=np.float64)\n",
    "x_scale = rng_scale.standard_normal(N, dtype=np.float64)\n",
    "A_scale = rng_scale.standard_normal((N, N), dtype=np.float64)\n",
    "B_scale = rng_scale.standard_normal((N, N), dtype=np.float64)\n",
    "\n",
    "def _bench_matvec(repeats=20):\n",
    "    times = []\n",
    "    _ = W_scale @ x_scale  # warmup\n",
    "    for _ in range(repeats):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = W_scale @ x_scale\n",
    "        times.append((time.perf_counter() - t0) * 1e3)\n",
    "    return np.asarray(times, dtype=np.float64)\n",
    "\n",
    "def _bench_matmul(repeats=5):\n",
    "    times = []\n",
    "    _ = A_scale @ B_scale  # warmup\n",
    "    for _ in range(repeats):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = A_scale @ B_scale\n",
    "        times.append((time.perf_counter() - t0) * 1e3)\n",
    "    return np.asarray(times, dtype=np.float64)\n",
    "\n",
    "matvec_ms = _bench_matvec()\n",
    "matmul_ms = _bench_matmul()\n",
    "\n",
    "print(f\"Matrix size: {N}x{N}\")\n",
    "print(f\"MatVec (W @ x) p50 / p95: {np.percentile(matvec_ms, 50):.3f} / {np.percentile(matvec_ms, 95):.3f} ms\")\n",
    "print(f\"MatMul (A @ B) p50 / p95: {np.percentile(matmul_ms, 50):.3f} / {np.percentile(matmul_ms, 95):.3f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Physics Integration with GS Solver Output\n",
    "\n",
    "The controller path below is connected to `FusionKernel.solve_equilibrium()` output.\n",
    "We generate synthetic diagnostics from the solved equilibrium and use them as control inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "from scpn_fusion.core import FusionKernel\n",
    "from scpn_fusion.diagnostics.forward import generate_forward_channels\n",
    "\n",
    "\n",
    "def _result_get(result, key, default=None):\n",
    "    if isinstance(result, dict):\n",
    "        return result.get(key, default)\n",
    "    return getattr(result, key, default)\n",
    "\n",
    "\n",
    "gs_config = {\n",
    "    \"reactor_name\": \"ITER-like\",\n",
    "    \"grid_resolution\": [65, 65],\n",
    "    \"dimensions\": {\"R_min\": 1.0, \"R_max\": 9.0, \"Z_min\": -5.0, \"Z_max\": 5.0},\n",
    "    \"physics\": {\"plasma_current_target\": 15.0, \"vacuum_permeability\": 1.2566370614e-6},\n",
    "    \"coils\": [\n",
    "        {\"r\": 3.5, \"z\": 4.0, \"current\": 5.0},\n",
    "        {\"r\": 3.5, \"z\": -4.0, \"current\": 5.0},\n",
    "        {\"r\": 9.0, \"z\": 4.0, \"current\": -3.0},\n",
    "        {\"r\": 9.0, \"z\": -4.0, \"current\": -3.0},\n",
    "        {\"r\": 6.2, \"z\": 5.5, \"current\": -1.5},\n",
    "        {\"r\": 6.2, \"z\": -5.5, \"current\": -1.5},\n",
    "    ],\n",
    "    \"solver\": {\n",
    "        \"max_iterations\": 80,\n",
    "        \"convergence_threshold\": 1e-6,\n",
    "        \"relaxation_factor\": 0.1,\n",
    "        \"solver_method\": \"multigrid\",\n",
    "    },\n",
    "}\n",
    "\n",
    "fd, gs_path = tempfile.mkstemp(suffix=\".json\")\n",
    "os.close(fd)\n",
    "with open(gs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gs_config, f)\n",
    "\n",
    "kernel = FusionKernel(gs_path)\n",
    "if hasattr(kernel, \"initialize_grid\"):\n",
    "    kernel.initialize_grid()\n",
    "if hasattr(kernel, \"calculate_vacuum_field\"):\n",
    "    kernel.calculate_vacuum_field()\n",
    "\n",
    "gs_result = kernel.solve_equilibrium()\n",
    "\n",
    "psi_gs = np.asarray(kernel.Psi, dtype=np.float64).copy()\n",
    "R = np.asarray(kernel.R, dtype=np.float64).copy()\n",
    "Z = np.asarray(kernel.Z, dtype=np.float64).copy()\n",
    "RR, ZZ = np.meshgrid(R, Z)\n",
    "\n",
    "axis_r = _result_get(gs_result, \"axis_r\")\n",
    "axis_z = _result_get(gs_result, \"axis_z\")\n",
    "psi_axis = _result_get(gs_result, \"psi_axis\")\n",
    "if axis_r is None or axis_z is None:\n",
    "    axis_candidate = kernel.find_x_point(psi_gs)\n",
    "    if isinstance(axis_candidate, tuple) and len(axis_candidate) == 3:\n",
    "        axis_r, axis_z, psi_axis = axis_candidate\n",
    "    else:\n",
    "        (axis_r, axis_z), psi_axis = axis_candidate\n",
    "\n",
    "axis_r = float(axis_r)\n",
    "axis_z = float(axis_z)\n",
    "\n",
    "gs_residual_value = float(_result_get(gs_result, \"gs_residual\", _result_get(gs_result, \"residual\", np.nan)))\n",
    "if not np.isfinite(gs_residual_value):\n",
    "    gs_residual_value = 1.0e-3\n",
    "\n",
    "psi_min = float(np.min(psi_gs))\n",
    "psi_max = float(np.max(psi_gs))\n",
    "psi_norm = (psi_gs - psi_min) / max(psi_max - psi_min, 1e-12)\n",
    "electron_density = 1.0e19 * (1.2 + 0.8 * (1.0 - psi_norm))\n",
    "neutron_source = 1.0e17 * np.clip(1.1 - psi_norm, 0.0, None)\n",
    "interferometer_chords = [\n",
    "    ((float(R[0]), float(z0)), (float(R[-1]), float(z0)))\n",
    "    for z0 in np.linspace(float(np.min(Z)) * 0.4, float(np.max(Z)) * 0.4, 8)\n",
    "]\n",
    "dV = float((R[1] - R[0]) * (Z[1] - Z[0]) * 2.0 * np.pi * np.mean(R))\n",
    "\n",
    "forward_channels = generate_forward_channels(\n",
    "    electron_density_m3=electron_density,\n",
    "    neutron_source_m3_s=neutron_source,\n",
    "    r_grid=R,\n",
    "    z_grid=Z,\n",
    "    interferometer_chords=interferometer_chords,\n",
    "    volume_element_m3=dV,\n",
    ")\n",
    "\n",
    "print(f\"GS converged: {bool(_result_get(gs_result, 'converged', False))}  iterations: {int(_result_get(gs_result, 'iterations', -1))}\")\n",
    "print(f\"GS residual (used for pipeline): {gs_residual_value:.3e}\")\n",
    "print(f\"Axis estimate: R={axis_r:.3f} m, Z={axis_z:.3f} m\")\n",
    "print(f\"Interferometer channels: {forward_channels.interferometer_phase_rad.shape[0]}\")\n",
    "print(f\"Neutron rate: {forward_channels.neutron_count_rate_hz:.3e} Hz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "levels = np.linspace(float(np.min(psi_gs)), float(np.max(psi_gs)), 30)\n",
    "cs = ax.contour(RR, ZZ, psi_gs, levels=levels, cmap=\"viridis\")\n",
    "ax.plot(axis_r, axis_z, \"rx\", markersize=10, label=\"Axis estimate\")\n",
    "ax.set_xlabel(\"R [m]\")\n",
    "ax.set_ylabel(\"Z [m]\")\n",
    "ax.set_title(\"GS Equilibrium used for Diagnostics\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.colorbar(cs, label=\"Psi [Wb/rad]\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: End-to-End Toy Pipeline Latency\n",
    "\n",
    "This section includes the full toy path per control tick:\n",
    "1. Sensor preprocessing (diagnostics)\n",
    "2. Physics model evaluation (equilibrium state features)\n",
    "3. Neuro-symbolic forward pass\n",
    "4. Actuator lag compensation\n",
    "\n",
    "This is intentionally broader than NN-only forward timing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_in_dense = compiled.W_in.toarray() if hasattr(compiled.W_in, \"toarray\") else np.asarray(compiled.W_in, dtype=np.float64)\n",
    "W_out_dense = compiled.W_out.toarray() if hasattr(compiled.W_out, \"toarray\") else np.asarray(compiled.W_out, dtype=np.float64)\n",
    "base_sensor = np.asarray(forward_channels.interferometer_phase_rad, dtype=np.float64)\n",
    "if base_sensor.size < 8:\n",
    "    base_sensor = np.pad(base_sensor, (0, 8 - base_sensor.size), mode=\"edge\")\n",
    "\n",
    "\n",
    "def preprocess_diagnostics(raw_sensor: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(raw_sensor, dtype=np.float64)\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    med = float(np.median(x))\n",
    "    mad = float(np.median(np.abs(x - med)))\n",
    "    scale = max(1.4826 * mad, 1e-9)\n",
    "    return np.clip((x - med) / scale, -4.0, 4.0)\n",
    "\n",
    "\n",
    "def evaluate_equilibrium_state(preprocessed: np.ndarray, gs_residual: float) -> tuple[float, float]:\n",
    "    radial_metric = float(np.mean(preprocessed[:4]))\n",
    "    vertical_metric = float(np.mean(preprocessed[4:8]))\n",
    "    stability = float(np.clip(gs_residual / 1.0e-3, 0.0, 1.0))\n",
    "    radial_error = float(np.tanh(radial_metric * (1.0 + 0.2 * stability)))\n",
    "    vertical_error = float(np.tanh(vertical_metric * (1.0 + 0.2 * stability)))\n",
    "    return radial_error, vertical_error\n",
    "\n",
    "\n",
    "def build_marking_inputs(radial_error: float, vertical_error: float) -> np.ndarray:\n",
    "    return np.array([\n",
    "        np.clip(radial_error, 0.0, 1.0),\n",
    "        np.clip(-radial_error, 0.0, 1.0),\n",
    "        np.clip(vertical_error, 0.0, 1.0),\n",
    "        np.clip(-vertical_error, 0.0, 1.0),\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "\n",
    "def lag_compensate(desired: np.ndarray, prev_desired: np.ndarray, dt: float = 1e-3, tau: float = 4e-3) -> np.ndarray:\n",
    "    return desired + (tau / max(dt, 1e-9)) * (desired - prev_desired)\n",
    "\n",
    "\n",
    "def actuator_apply(command: np.ndarray, prev_applied: np.ndarray, dt: float = 1e-3, tau: float = 6e-3) -> np.ndarray:\n",
    "    alpha = dt / (tau + dt)\n",
    "    return prev_applied + alpha * (command - prev_applied)\n",
    "\n",
    "\n",
    "gs_residual_for_chain = float(gs_residual_value) if \"gs_residual_value\" in globals() else 1.0e-3\n",
    "if not np.isfinite(gs_residual_for_chain):\n",
    "    gs_residual_for_chain = 1.0e-3\n",
    "\n",
    "rng_chain = np.random.default_rng(123)\n",
    "n_steps = 1000\n",
    "marking = np.zeros(compiled.n_places, dtype=np.float64)\n",
    "prev_desired = np.zeros(4, dtype=np.float64)\n",
    "applied = np.zeros(4, dtype=np.float64)\n",
    "\n",
    "lat_nn_ms = np.zeros(n_steps, dtype=np.float64)\n",
    "lat_e2e_ms = np.zeros(n_steps, dtype=np.float64)\n",
    "applied_trace = np.zeros((n_steps, 4), dtype=np.float64)\n",
    "\n",
    "for k in range(n_steps):\n",
    "    t_chain0 = time.perf_counter()\n",
    "    disturbance = 0.03 * np.sin(2.0 * np.pi * k / 200.0)\n",
    "    raw_sensor = base_sensor * (1.0 + disturbance) + rng_chain.normal(0.0, 1e-4, size=base_sensor.shape)\n",
    "    pre = preprocess_diagnostics(raw_sensor)\n",
    "    r_err, z_err = evaluate_equilibrium_state(pre, gs_residual_for_chain)\n",
    "\n",
    "    marking[:] = 0.0\n",
    "    marking[:4] = build_marking_inputs(r_err, z_err)\n",
    "\n",
    "    t_nn0 = time.perf_counter()\n",
    "    currents = W_in_dense @ marking\n",
    "    fired = (currents >= compiled.thresholds).astype(np.float64)\n",
    "    consumed = W_in_dense.T @ fired\n",
    "    produced = W_out_dense @ fired\n",
    "    new_marking = np.clip(marking - consumed + produced, 0.0, 1.0)\n",
    "    desired = new_marking[4:8]\n",
    "    t_nn1 = time.perf_counter()\n",
    "\n",
    "    compensated = lag_compensate(desired, prev_desired)\n",
    "    applied = actuator_apply(compensated, applied)\n",
    "    prev_desired = desired\n",
    "    applied_trace[k, :] = applied\n",
    "\n",
    "    lat_nn_ms[k] = (t_nn1 - t_nn0) * 1e3\n",
    "    lat_e2e_ms[k] = (time.perf_counter() - t_chain0) * 1e3\n",
    "\n",
    "print(\"Toy pipeline latency over 1000 control ticks:\")\n",
    "print(f\"  NN forward only p50/p95: {np.percentile(lat_nn_ms, 50):.4f} / {np.percentile(lat_nn_ms, 95):.4f} ms\")\n",
    "print(f\"  End-to-end p50/p95:      {np.percentile(lat_e2e_ms, 50):.4f} / {np.percentile(lat_e2e_ms, 95):.4f} ms\")\n",
    "ratio = np.percentile(lat_e2e_ms, 95) / max(np.percentile(lat_nn_ms, 95), 1e-9)\n",
    "print(f\"  End-to-end / NN p95 ratio: {ratio:.2f}x\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(lat_nn_ms, bins=40, alpha=0.7, label=\"NN forward\")\n",
    "axes[0].hist(lat_e2e_ms, bins=40, alpha=0.7, label=\"End-to-end\")\n",
    "axes[0].set_xlabel(\"Latency [ms]\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Latency Distribution\")\n",
    "axes[0].legend()\n",
    "axes[1].plot(applied_trace[:, 0], label=\"PF_up\")\n",
    "axes[1].plot(applied_trace[:, 1], label=\"PF_down\")\n",
    "axes[1].plot(applied_trace[:, 2], label=\"PF_in\")\n",
    "axes[1].plot(applied_trace[:, 3], label=\"PF_out\")\n",
    "axes[1].set_xlabel(\"Step\")\n",
    "axes[1].set_ylabel(\"Applied command\")\n",
    "axes[1].set_title(\"Lag-Compensated Actuator Trace\")\n",
    "axes[1].legend(loc=\"upper right\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Scope Clarification\n",
    "\n",
    "This notebook now demonstrates both:\n",
    "- Neural net forward-pass latency\n",
    "- End-to-end toy latency (diagnostics -> equilibrium features -> neural net -> lag compensation)\n",
    "\n",
    "Real deployment would still require:\n",
    "- Sensor preprocessing and diagnostics integration on live streams\n",
    "- Physics model evaluation against live equilibrium state\n",
    "- Actuator lag compensation tuned to plant hardware\n",
    "- Full DAQ/network/actuator timing budget verification\n",
    "\n",
    "Copyright clarity:\n",
    "- Concepts: Copyright 1996-2026\n",
    "- Code: Copyright 2024-2026\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"gs_path\" in globals() and isinstance(gs_path, str) and os.path.exists(gs_path):\n",
    "    os.unlink(gs_path)\n",
    "    print(f\"Cleaned up temporary config: {gs_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
