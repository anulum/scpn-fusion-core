# CopyRight: (c) 1998-2026 Miroslav Sotek. All rights reserved.
# ----------------------------------------------------------------------
# SCPN Fusion Core -- Forward Solve Validation
# Contact: www.anulum.li | protoscience@anulum.li
# ORCID: https://orcid.org/0009-0009-3560-0851
# License: GNU AGPL v3 | Commercial licensing available
# ----------------------------------------------------------------------
"""Forward solve validation: compare our GS solver against ground truth.

For each synthetic shot, we feed the same source profiles (p', FF') to
our Picard+SOR solver and compare the resulting psi(R,Z) to the known
ground truth generated by the Solov'ev analytical solution.

The Solov'ev ground truth is computed in normalised coordinates
(x = R/R0, y = Z/R0) using the Cerfon-Freidberg (2010) formulation.
The particular solutions satisfy:

    Delta*_xy(x^4/8) = x^2              [pressure source]
    Delta*_xy((1/2)x^2 ln(x) - x^4/8) = 1 - x^2  [FF' source]

so the combined solution satisfies:

    Delta*_xy(psi_raw) = x^2 + A*(1 - x^2) = x^2*(1 - A) + A

Converting to physical coordinates (R, Z) with the physical scaling:

    Delta*_RZ(psi_phys) = (S / R0^2) * [(R/R0)^2 * (1 - A) + A]

where S is the composite scale factor from the generator.

Usage:
    python validation/run_forward_validation.py [--shots-dir validation/synthetic_shots]
"""

from __future__ import annotations

import argparse
import csv
import json
import sys
import time
from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
from numpy.typing import NDArray

# ── Physical constants ────────────────────────────────────────────────

MU_0 = 4.0 * np.pi * 1e-7  # vacuum permeability [H/m]


# =====================================================================
# Picard + SOR Forward Solver (Python fallback)
# =====================================================================
#
# The Rust solver (scpn_fusion_rs) requires a JSON config with coil
# definitions and uses free-boundary equilibrium iteration.  For this
# validation we need a *fixed-profile* forward solve on arbitrary grids,
# so we implement a pure-Python Picard + Red-Black SOR solver that
# matches the Rust stencil from fusion-math/src/sor.rs.
#
# GS equation in cylindrical (R, Z):
#   R d/dR(1/R dPsi/dR) + d^2 Psi/dZ^2 = source(R, Z)
#
# Expanding the left side:
#   d^2 Psi/dR^2 - (1/R) dPsi/dR + d^2 Psi/dZ^2 = source(R, Z)
#
# 5-point stencil (matching Rust sor.rs update_point):
#   c_R+   = 1/dR^2 - 1/(2*R*dR)        (right neighbour)
#   c_R-   = 1/dR^2 + 1/(2*R*dR)        (left neighbour)
#   c_Z    = 1/dZ^2                      (up/down neighbours)
#   center = 2/dR^2 + 2/dZ^2            (diagonal coefficient)
#
# Index convention: axis-0 = Z, axis-1 = R (matching Rust layout).


def _sor_sweep_vectorised(
    psi: NDArray,
    source: NDArray,
    RR: NDArray,
    dr: float,
    dz: float,
    omega: float,
) -> None:
    """One full Red-Black SOR iteration using vectorised NumPy.

    This is substantially faster than pure-Python nested loops for
    grids of size 65x65 and above.  The stencil is identical to the
    Rust sor.rs implementation.
    """
    nz, nr = psi.shape
    dr_sq = dr * dr
    dz_sq = dz * dz
    c_z = 1.0 / dz_sq
    center = 2.0 / dr_sq + 2.0 / dz_sq

    R_inner = RR[1:-1, 1:-1]  # (nz-2, nr-2)
    c_r_plus = 1.0 / dr_sq - 1.0 / (2.0 * R_inner * dr)
    c_r_minus = 1.0 / dr_sq + 1.0 / (2.0 * R_inner * dr)

    # Build checkerboard mask (computed once, cached implicitly by NumPy)
    iz_idx = np.arange(1, nz - 1)[:, np.newaxis]
    ir_idx = np.arange(1, nr - 1)[np.newaxis, :]
    parity = (iz_idx + ir_idx) % 2  # 0 = red, 1 = black

    interior = psi[1:-1, 1:-1]
    src = source[1:-1, 1:-1]

    for color in (0, 1):
        # Recompute neighbour references (pick up updates from previous pass)
        p_up = psi[2:, 1:-1]
        p_down = psi[:-2, 1:-1]
        p_right = psi[1:-1, 2:]
        p_left = psi[1:-1, :-2]

        p_star = (
            -src
            + c_z * (p_up + p_down)
            + c_r_plus * p_right
            + c_r_minus * p_left
        ) / center

        mask = parity == color
        interior[mask] = (1.0 - omega) * interior[mask] + omega * p_star[mask]


# ── Numba JIT-compiled SOR sweep (10-50x faster) ─────────────────────

_USE_NUMBA = False
try:
    import numba

    @numba.njit(cache=True)
    def _sor_sweep_numba(
        psi: np.ndarray,
        source: np.ndarray,
        RR: np.ndarray,
        dr: float,
        dz: float,
        omega: float,
    ) -> None:
        """Numba JIT Red-Black SOR sweep with GS cylindrical stencil."""
        nz = psi.shape[0]
        nr = psi.shape[1]
        dr_sq = dr * dr
        dz_sq = dz * dz
        c_z = 1.0 / dz_sq
        center = 2.0 / dr_sq + 2.0 / dz_sq

        for color in range(2):  # 0=red, 1=black
            for iz in range(1, nz - 1):
                for ir in range(1, nr - 1):
                    if (iz + ir) % 2 != color:
                        continue
                    R_val = RR[iz, ir]
                    c_r_plus = 1.0 / dr_sq - 1.0 / (2.0 * R_val * dr)
                    c_r_minus = 1.0 / dr_sq + 1.0 / (2.0 * R_val * dr)
                    p_star = (
                        -source[iz, ir]
                        + c_z * (psi[iz + 1, ir] + psi[iz - 1, ir])
                        + c_r_plus * psi[iz, ir + 1]
                        + c_r_minus * psi[iz, ir - 1]
                    ) / center
                    psi[iz, ir] = (1.0 - omega) * psi[iz, ir] + omega * p_star

    _USE_NUMBA = True
except ImportError:
    pass


def _sor_sweep(
    psi: NDArray,
    source: NDArray,
    RR: NDArray,
    dr: float,
    dz: float,
    omega: float,
) -> None:
    """Dispatch to Numba JIT if available, else vectorised NumPy."""
    if _USE_NUMBA:
        _sor_sweep_numba(psi, source, RR, dr, dz, omega)
    else:
        _sor_sweep_vectorised(psi, source, RR, dr, dz, omega)


def _apply_bc(psi: NDArray, bc: NDArray) -> None:
    """Apply Dirichlet boundary conditions in place."""
    psi[0, :] = bc[0, :]
    psi[-1, :] = bc[-1, :]
    psi[:, 0] = bc[:, 0]
    psi[:, -1] = bc[:, -1]


def _build_initial_guess(bc: NDArray, nz: int, nr: int) -> NDArray:
    """Build a smooth initial guess from boundary values.

    Uses bilinear blending of the four boundary edges to create a
    smooth starting field that is compatible with the BCs and speeds
    SOR convergence.
    """
    fz = np.linspace(0.0, 1.0, nz)[:, np.newaxis]  # (nz, 1)
    fr = np.linspace(0.0, 1.0, nr)[np.newaxis, :]  # (1, nr)

    top = bc[0, :][np.newaxis, :]
    bot = bc[-1, :][np.newaxis, :]
    left = bc[:, 0][:, np.newaxis]
    right = bc[:, -1][:, np.newaxis]

    psi = (
        (1 - fz) * top + fz * bot
        + (1 - fr) * left + fr * right
        - (1 - fz) * (1 - fr) * bc[0, 0]
        - (1 - fz) * fr * bc[0, -1]
        - fz * (1 - fr) * bc[-1, 0]
        - fz * fr * bc[-1, -1]
    )
    return psi


def _find_axis_indices(psi: NDArray) -> Tuple[int, int, float]:
    """Find magnetic axis location and value in (nz, nr) layout."""
    idx_min = np.unravel_index(np.argmin(psi), psi.shape)
    idx_max = np.unravel_index(np.argmax(psi), psi.shape)
    psi_min = float(psi[idx_min])
    psi_max = float(psi[idx_max])
    if abs(psi_min) >= abs(psi_max):
        return int(idx_min[0]), int(idx_min[1]), psi_min
    else:
        return int(idx_max[0]), int(idx_max[1]), psi_max


def _find_axis_subgrid(
    psi: NDArray,
    r_grid: NDArray,
    z_grid: NDArray,
) -> Tuple[float, float, float]:
    """Find magnetic axis with quadratic subgrid interpolation.

    Fits independent 1-D parabolas along R and Z through the 3-point
    neighbourhood of the discrete extremum.  Returns sub-pixel
    (r_axis, z_axis, psi_axis) in physical coordinates.

    Parameters
    ----------
    psi : (nz, nr) or (nr, nz) array
    r_grid, z_grid : 1-D coordinate arrays

    Returns
    -------
    r_axis, z_axis, psi_axis
    """
    nz, nr = psi.shape

    # Discrete extremum — our convention: psi < 0 at axis, ~0 on boundary.
    # Always use argmin (the most negative point is the magnetic axis).
    idx_min = np.unravel_index(np.argmin(psi), psi.shape)
    iz0, ir0 = int(idx_min[0]), int(idx_min[1])

    dr = float(r_grid[1] - r_grid[0])
    dz = float(z_grid[1] - z_grid[0])

    r_axis = float(r_grid[ir0])
    z_axis = float(z_grid[iz0])

    # Quadratic fit along R (3-point parabola)
    if 1 <= ir0 < nr - 1:
        fL = psi[iz0, ir0 - 1]
        fC = psi[iz0, ir0]
        fR = psi[iz0, ir0 + 1]
        denom = fR - 2.0 * fC + fL
        if abs(denom) > 1e-30:
            shift = -0.5 * (fR - fL) / denom
            shift = max(-0.5, min(0.5, shift))
            r_axis += shift * dr

    # Quadratic fit along Z (3-point parabola)
    if 1 <= iz0 < nz - 1:
        fD = psi[iz0 - 1, ir0]
        fC = psi[iz0, ir0]
        fU = psi[iz0 + 1, ir0]
        denom = fU - 2.0 * fC + fD
        if abs(denom) > 1e-30:
            shift = -0.5 * (fU - fD) / denom
            shift = max(-0.5, min(0.5, shift))
            z_axis += shift * dz

    # Interpolated psi value at subgrid axis
    psi_axis = float(psi[iz0, ir0])

    return r_axis, z_axis, psi_axis


def _compute_solovev_source(
    RR: NDArray,
    R0: float,
    A_param: float,
    scale_factor: float,
) -> NDArray:
    """Compute the GS source term for a Solov'ev equilibrium.

    The Cerfon-Freidberg (2010) particular solutions satisfy:
        Delta*_xy(psi_p)  = x^2          where psi_p  = x^4/8
        Delta*_xy(psi_ff) = 1 - x^2      where psi_ff = (1/2)x^2 ln(x) - x^4/8

    Combined solution:  Delta*_xy(psi_raw) = x^2 + A*(1 - x^2)

    In physical coordinates with the applied scale_factor S:
        Delta*_RZ(psi_phys) = (S / R0^2) * [(R/R0)^2 * (1 - A) + A]

    Parameters
    ----------
    RR : (nz, nr) array
        2-D R coordinate mesh [m].
    R0 : float
        Major radius [m].
    A_param : float
        Cerfon-Freidberg A parameter controlling p'/FF' balance.
    scale_factor : float
        Composite scale factor S such that psi_phys = S * psi_raw.
        This includes the sign flip (if any) and the psi_scale
        normalisation applied by the generator.

    Returns
    -------
    source : (nz, nr) array
        GS source term on the (Z, R) grid.
    """
    x = RR / R0
    return (scale_factor / R0**2) * (x**2 * (1.0 - A_param) + A_param)


def _compute_source_manufactured(
    psi_ref: NDArray,
    r_grid: NDArray,
    z_grid: NDArray,
) -> NDArray:
    """Compute the GS source by applying the discrete GS operator to psi_ref.

    This is the "manufactured solution" approach: we compute the discrete
    residual Delta*_h(psi_ref) exactly on the finite-difference stencil,
    so the source is perfectly consistent with the discrete operator.
    This eliminates source-term truncation error from the validation.

    Parameters
    ----------
    psi_ref : (nr, nz) array
        Reference psi in (axis-0 = R, axis-1 = Z) layout.
    r_grid : (nr,) array
        R coordinate values [m].
    z_grid : (nz,) array
        Z coordinate values [m].

    Returns
    -------
    source : (nr, nz) array
        Discrete GS source: Delta*_h(psi_ref).
    """
    nr, nz = psi_ref.shape
    dr = float(r_grid[1] - r_grid[0])
    dz = float(z_grid[1] - z_grid[0])
    dr_sq = dr * dr
    dz_sq = dz * dz

    source = np.zeros_like(psi_ref)

    for ir in range(1, nr - 1):
        R = r_grid[ir]
        c_r_plus = 1.0 / dr_sq - 1.0 / (2.0 * R * dr)
        c_r_minus = 1.0 / dr_sq + 1.0 / (2.0 * R * dr)
        c_z = 1.0 / dz_sq
        center = 2.0 / dr_sq + 2.0 / dz_sq

        for iz in range(1, nz - 1):
            source[ir, iz] = (
                c_r_plus * psi_ref[ir + 1, iz]
                + c_r_minus * psi_ref[ir - 1, iz]
                + c_z * (psi_ref[ir, iz + 1] + psi_ref[ir, iz - 1])
                - center * psi_ref[ir, iz]
            )

    return source


def _compute_source_manufactured_vectorised(
    psi_ref: NDArray,
    r_grid: NDArray,
    z_grid: NDArray,
) -> NDArray:
    """Vectorised version of _compute_source_manufactured.

    Computes source = Delta*_h(psi_ref) using the same 5-point stencil
    as the SOR solver, but in fully vectorised NumPy.

    Parameters
    ----------
    psi_ref : (nr, nz) array
        Reference psi (axis-0 = R, axis-1 = Z).
    r_grid, z_grid : 1-D arrays.

    Returns
    -------
    source : (nr, nz) array
    """
    nr, nz = psi_ref.shape
    dr = float(r_grid[1] - r_grid[0])
    dz = float(z_grid[1] - z_grid[0])
    dr_sq = dr * dr
    dz_sq = dz * dz

    R_inner = r_grid[1:-1]  # (nr-2,)
    c_r_plus = (1.0 / dr_sq - 1.0 / (2.0 * R_inner * dr))[:, np.newaxis]
    c_r_minus = (1.0 / dr_sq + 1.0 / (2.0 * R_inner * dr))[:, np.newaxis]
    c_z = 1.0 / dz_sq
    center = 2.0 / dr_sq + 2.0 / dz_sq

    source = np.zeros_like(psi_ref)
    source[1:-1, 1:-1] = (
        c_r_plus * psi_ref[2:, 1:-1]
        + c_r_minus * psi_ref[:-2, 1:-1]
        + c_z * (psi_ref[1:-1, 2:] + psi_ref[1:-1, :-2])
        - center * psi_ref[1:-1, 1:-1]
    )

    return source


def _compute_gs_source_general(
    psi: NDArray,
    RR: NDArray,
    p_prime: NDArray,
    ff_prime: NDArray,
    psi_axis: float,
    psi_boundary: float,
) -> NDArray:
    """Compute the GS source for general (non-constant) profiles.

    Used when p'(psi) and FF'(psi) vary with normalised psi.

    Returns source = -mu0 * R^2 * p'(psi_n) - FF'(psi_n)
    """
    nz, nr = psi.shape
    denom = psi_boundary - psi_axis
    if abs(denom) < 1e-30:
        denom = 1e-30
    psi_n = np.clip((psi - psi_axis) / denom, 0.0, 1.0)

    n_prof = len(p_prime)
    psi_n_prof = np.linspace(0.0, 1.0, n_prof)
    p2d = np.interp(psi_n.ravel(), psi_n_prof, p_prime).reshape(nz, nr)
    ff2d = np.interp(psi_n.ravel(), psi_n_prof, ff_prime).reshape(nz, nr)

    return -MU_0 * RR**2 * p2d - ff2d


def picard_sor_solve(
    r_grid: NDArray,
    z_grid: NDArray,
    source_2d: NDArray,
    psi_boundary: NDArray,
    psi_init: Optional[NDArray] = None,
    max_iter: int = 10000,
    omega: float = 1.7,
    tol: float = 1e-8,
    check_every: int = 200,
) -> dict:
    """Simple Picard + SOR GS solver for validation.

    GS equation: d^2 psi/dR^2 - (1/R) dpsi/dR + d^2 psi/dZ^2 = source

    For constant source terms (Solov'ev case), this reduces to a single
    linear elliptic PDE solved directly by Red-Black SOR.

    Parameters
    ----------
    r_grid : (nr,) array
        Radial coordinate values [m].
    z_grid : (nz,) array
        Vertical coordinate values [m].
    source_2d : (nz, nr) or (nr, nz) array
        Pre-computed RHS source term for the GS equation.
    psi_boundary : (nz, nr) or (nr, nz) array
        Reference psi used for Dirichlet boundary values on grid edges.
    psi_init : optional array
        Initial guess for psi interior.  If None, bilinear blend of BC.
    max_iter : int
        Maximum SOR iterations.
    omega : float
        SOR relaxation factor (1 < omega < 2 for over-relaxation).
    tol : float
        Convergence tolerance on max |psi_new - psi_old|.
    check_every : int
        How often (in iterations) to check convergence.

    Returns
    -------
    dict with keys:
        psi_rz, r_grid, z_grid, r_axis, z_axis, psi_axis,
        converged, iterations, residual
    """
    nr = len(r_grid)
    nz = len(z_grid)
    dr = float(r_grid[1] - r_grid[0])
    dz = float(z_grid[1] - z_grid[0])

    # Build 2-D R mesh: psi[iz, ir] convention
    RR = np.ones((nz, 1)) * r_grid[np.newaxis, :]

    # Prepare source in (nz, nr) layout
    src = np.asarray(source_2d, dtype=np.float64)
    if src.shape == (nr, nz):
        src = src.T.copy()

    # Prepare BC array in (nz, nr) layout
    psi_bc = np.asarray(psi_boundary, dtype=np.float64)
    if psi_bc.shape == (nr, nz):
        psi_bc = psi_bc.T

    bc = np.zeros((nz, nr))
    bc[0, :] = psi_bc[0, :]
    bc[-1, :] = psi_bc[-1, :]
    bc[:, 0] = psi_bc[:, 0]
    bc[:, -1] = psi_bc[:, -1]

    # Zero source on boundary rows/cols
    src[0, :] = 0.0
    src[-1, :] = 0.0
    src[:, 0] = 0.0
    src[:, -1] = 0.0

    # Initialise psi
    if psi_init is not None:
        psi_in = np.asarray(psi_init, dtype=np.float64)
        psi = psi_in.T.copy() if psi_in.shape == (nr, nz) else psi_in.copy()
    else:
        psi = _build_initial_guess(bc, nz, nr)
    _apply_bc(psi, bc)

    # SOR iteration loop
    converged = False
    final_residual = 1e30

    psi_snapshot = psi.copy()
    for it in range(1, max_iter + 1):
        _sor_sweep(psi, src, RR, dr, dz, omega)
        _apply_bc(psi, bc)

        if it % check_every == 0:
            diff = float(np.max(np.abs(psi - psi_snapshot)))
            final_residual = diff
            if diff < tol:
                converged = True
                break
            psi_snapshot = psi.copy()

    # Final residual
    if not converged:
        psi_check = psi.copy()
        _sor_sweep(psi_check, src, RR, dr, dz, omega)
        _apply_bc(psi_check, bc)
        final_residual = float(np.max(np.abs(psi_check - psi)))
        psi = psi_check

    # Find magnetic axis (subgrid quadratic interpolation)
    r_axis, z_axis, psi_axis_final = _find_axis_subgrid(psi, r_grid, z_grid)

    # Transpose back to (nr, nz) to match synthetic shot convention
    psi_out = psi.T

    return {
        "psi_rz": psi_out,
        "r_grid": r_grid,
        "z_grid": z_grid,
        "r_axis": r_axis,
        "z_axis": z_axis,
        "psi_axis": psi_axis_final,
        "converged": converged,
        "iterations": it,
        "residual": final_residual,
    }


# =====================================================================
# Shot loader
# =====================================================================

@dataclass
class ShotData:
    """Container for a single synthetic shot's data."""
    shot_id: str
    category: str
    description: str
    r_grid: NDArray
    z_grid: NDArray
    psi_rz: NDArray          # (nr, nz) convention
    p_prime: NDArray
    ff_prime: NDArray
    probe_r: NDArray
    probe_z: NDArray
    probe_psi: NDArray
    boundary_r: NDArray
    boundary_z: NDArray
    r_axis: float
    z_axis: float
    psi_axis: float
    R0: float
    a: float
    B0: float
    Ip: float
    kappa: float
    delta: float
    beta_N: float
    A_param: float           # Cerfon-Freidberg A parameter
    scale_factor: float      # composite scale: psi_phys = scale * psi_raw


def _compute_scale_factor(meta: dict, psi_rz: NDArray, r_grid: NDArray,
                          z_grid: NDArray) -> float:
    """Reconstruct the composite scale factor S from shot metadata.

    The generator applies:
        1. boundary shift: psi_raw -= bdry_mean
        2. sign flip: psi_shifted = -psi_shifted  (if center > 0)
        3. physical scaling: psi_phys = scale_factor * psi_shifted

    The resulting S accounts for steps 2-3 combined.  We reconstruct it
    from the known analytical form at the grid center.
    """
    R0 = float(meta["R0_m"])
    A_param = float(meta["A_param"])

    # psi_raw in normalised coords at x=1, y=0 is:
    #   psi_raw_center = psi_p(1,0) + A * psi_ff(1,0) + sum c_k psi_hk(1,0)
    # The particular solutions at (1, 0):
    #   psi_p(1,0) = 1/8 = 0.125
    #   psi_ff(1,0) = 0.5*1*ln(1) - 1/8 = -0.125
    coeffs = meta["coefficients"]
    # Homogeneous solutions at x=1, y=0
    h_vals = [
        1.0,           # psi_h1 = 1
        1.0,           # psi_h2 = x^2 = 1
        0.0,           # psi_h3 = y^2 - x^2 ln(x) = 0
        1.0,           # psi_h4 = x^4 - 4x^2 y^2 = 1
        0.0,           # psi_h5: all terms have y^2 or ln(1), = 0
        1.0,           # psi_h6 = x^6 - 12x^4 y^2 + 8x^2 y^4 = 1
        -7.0 / 6.0,   # psi_h7: f6(1,0)*ln(1) + h(1,0) = 0 + (-7/6)
    ]
    psi_raw_center = 0.125 + A_param * (-0.125)
    for k in range(len(coeffs)):
        psi_raw_center += coeffs[k] * h_vals[k]

    # The boundary mean was subtracted, but we know psi on boundary ~= 0
    # by construction (lstsq fit), so bdry_mean ~= 0.  Any residual is
    # absorbed into the overall S.

    # Find the physical psi value at the grid center
    ir_center = np.argmin(np.abs(r_grid - R0))
    iz_center = np.argmin(np.abs(z_grid - 0.0))

    # psi_rz is (nr, nz) so [ir, iz]
    psi_phys_center = float(psi_rz[ir_center, iz_center])

    if abs(psi_raw_center) < 1e-30:
        # Fallback: use axis values
        Ip_A = float(meta["Ip_MA"]) * 1e6
        psi_scale = MU_0 * R0 * Ip_A / (2 * np.pi)
        return psi_scale
    else:
        return psi_phys_center / psi_raw_center


def load_shot(npz_path: Path, json_path: Path) -> ShotData:
    """Load a single synthetic shot from NPZ + JSON files."""
    with open(json_path, "r") as f:
        meta = json.load(f)

    data = np.load(npz_path)
    psi_rz = data["psi_rz"]
    r_grid = data["r_grid"]
    z_grid = data["z_grid"]

    scale_factor = _compute_scale_factor(meta, psi_rz, r_grid, z_grid)

    return ShotData(
        shot_id=meta["shot_id"],
        category=meta["category"],
        description=meta.get("description", ""),
        r_grid=r_grid,
        z_grid=z_grid,
        psi_rz=psi_rz,
        p_prime=data["p_prime"],
        ff_prime=data["ff_prime"],
        probe_r=data["probe_r"],
        probe_z=data["probe_z"],
        probe_psi=data["probe_psi"],
        boundary_r=data["boundary_r"],
        boundary_z=data["boundary_z"],
        r_axis=float(meta["r_axis_m"]),
        z_axis=float(meta["z_axis_m"]),
        psi_axis=float(meta["psi_axis"]),
        R0=float(meta["R0_m"]),
        a=float(meta["a_m"]),
        B0=float(meta["B0_T"]),
        Ip=float(meta["Ip_MA"]),
        kappa=float(meta["kappa"]),
        delta=float(meta["delta"]),
        beta_N=float(meta["beta_N"]),
        A_param=float(meta["A_param"]),
        scale_factor=scale_factor,
    )


def discover_shots(shots_dir: Path) -> List[Tuple[Path, Path]]:
    """Find all (NPZ, JSON) file pairs in the shots directory."""
    pairs = []
    for npz_path in sorted(shots_dir.glob("*.npz")):
        json_path = npz_path.with_suffix(".json")
        if json_path.exists():
            pairs.append((npz_path, json_path))
    return pairs


# =====================================================================
# Comparison helpers
# =====================================================================

def _normalised_psi_rmse(psi_ours: NDArray, psi_ref: NDArray) -> float:
    """Normalised RMSE: ||psi_ours - psi_ref||_2 / ||psi_ref||_2."""
    diff_norm = np.linalg.norm(psi_ours - psi_ref)
    ref_norm = np.linalg.norm(psi_ref)
    if ref_norm == 0.0:
        return 0.0 if diff_norm == 0.0 else float("inf")
    return float(diff_norm / ref_norm)


def _axis_error_m(
    psi: NDArray,
    r_grid: NDArray,
    z_grid: NDArray,
    r_axis_ref: float,
    z_axis_ref: float,
) -> dict:
    """Magnetic axis position error [m].

    psi is in (nr, nz) convention; axis-0 = R, axis-1 = Z.
    Uses quadratic subgrid interpolation for sub-pixel accuracy.
    """
    # Transpose to (nz, nr) for _find_axis_subgrid
    psi_nz_nr = psi.T
    r_axis, z_axis, _ = _find_axis_subgrid(psi_nz_nr, r_grid, z_grid)

    dr = r_axis - r_axis_ref
    dz = z_axis - z_axis_ref
    total = float(np.hypot(dr, dz))
    return {"dr_m": dr, "dz_m": dz, "total_m": total}


def _extract_zero_contour(
    psi: NDArray, r_grid: NDArray, z_grid: NDArray,
) -> Tuple[NDArray, NDArray]:
    """Extract approximate psi=0 contour via sign-change interpolation."""
    nr, nz = psi.shape
    r_pts, z_pts = [], []

    for j in range(nz):
        for i in range(nr - 1):
            if psi[i, j] * psi[i + 1, j] < 0:
                frac = abs(psi[i, j]) / (abs(psi[i, j]) + abs(psi[i + 1, j]))
                r_pts.append(r_grid[i] + frac * (r_grid[i + 1] - r_grid[i]))
                z_pts.append(z_grid[j])

    for i in range(nr):
        for j in range(nz - 1):
            if psi[i, j] * psi[i, j + 1] < 0:
                frac = abs(psi[i, j]) / (abs(psi[i, j]) + abs(psi[i, j + 1]))
                r_pts.append(r_grid[i])
                z_pts.append(z_grid[j] + frac * (z_grid[j + 1] - z_grid[j]))

    return np.array(r_pts), np.array(z_pts)


def run_full_comparison(ours: dict, ref_shot: ShotData) -> dict:
    """Run the comparison suite between our solve and the reference."""
    try:
        from equilibrium_comparison import (
            normalized_psi_rmse,
            axis_position_error,
            boundary_hausdorff,
        )
        has_comparison = True
    except ImportError:
        has_comparison = False

    # 1. Normalised psi RMSE
    if has_comparison:
        psi_rmse = normalized_psi_rmse(ours["psi_rz"], ref_shot.psi_rz)
    else:
        psi_rmse = _normalised_psi_rmse(ours["psi_rz"], ref_shot.psi_rz)

    # 2. Axis position error
    if has_comparison:
        axis_err = axis_position_error(
            ours["psi_rz"], ours["r_grid"], ours["z_grid"],
            ref_shot.r_axis, ref_shot.z_axis,
        )
    else:
        axis_err = _axis_error_m(
            ours["psi_rz"], ours["r_grid"], ours["z_grid"],
            ref_shot.r_axis, ref_shot.z_axis,
        )

    # 3. Boundary Hausdorff distance
    bdry_hausdorff_m = float("nan")
    if has_comparison:
        try:
            our_bdry_r, our_bdry_z = _extract_zero_contour(
                ours["psi_rz"], ours["r_grid"], ours["z_grid"],
            )
            if len(our_bdry_r) >= 3:
                bdry_hausdorff_m = boundary_hausdorff(
                    our_bdry_r, our_bdry_z,
                    ref_shot.boundary_r, ref_shot.boundary_z,
                )
        except Exception:
            pass

    # 4. Max absolute error
    max_abs_err = float(np.max(np.abs(ours["psi_rz"] - ref_shot.psi_rz)))

    # 5. Psi range for context
    psi_range_ref = float(np.max(ref_shot.psi_rz) - np.min(ref_shot.psi_rz))

    return {
        "normalized_psi_rmse": psi_rmse,
        "axis_error": axis_err,
        "boundary_hausdorff_m": bdry_hausdorff_m,
        "max_absolute_error": max_abs_err,
        "psi_range_ref": psi_range_ref,
        "solver_converged": ours["converged"],
        "solver_iterations": ours["iterations"],
        "solver_residual": ours["residual"],
    }


# =====================================================================
# Main validation loop
# =====================================================================

def run_forward_validation(
    shots_dir: Path,
    results_dir: Path,
    max_iter: int = 10000,
    omega: float = 1.7,
    tol: float = 1e-8,
    source_mode: str = "analytical",
) -> List[dict]:
    """Run forward solve validation on all synthetic shots.

    Parameters
    ----------
    shots_dir : Path
        Directory containing synthetic shot NPZ/JSON files.
    results_dir : Path
        Directory to write per-shot results and summary.
    max_iter : int
        Maximum SOR iterations per shot.
    omega : float
        SOR relaxation factor.
    tol : float
        Convergence tolerance.
    source_mode : str
        Source term mode: ``"analytical"`` uses the Solov'ev analytical
        source (tests full pipeline including discretisation error);
        ``"manufactured"`` applies the discrete GS stencil to the
        reference psi (tests only solver correctness, eliminating
        truncation error).

    Returns
    -------
    list of dict
        Per-shot result dictionaries.
    """
    results_dir.mkdir(parents=True, exist_ok=True)

    shot_pairs = discover_shots(shots_dir)
    if not shot_pairs:
        print(f"No shots found in {shots_dir}")
        return []

    n_shots = len(shot_pairs)
    print(f"Found {n_shots} synthetic shots in {shots_dir}")
    print(f"Results will be saved to {results_dir}")
    print(f"Solver settings: max_iter={max_iter}, omega={omega}, tol={tol}")
    print(f"Source mode: {source_mode}")
    print("-" * 78)

    all_results = []

    for idx, (npz_path, json_path) in enumerate(shot_pairs):
        shot = load_shot(npz_path, json_path)

        t0 = time.time()

        # Compute source term.
        nr = len(shot.r_grid)
        nz = len(shot.z_grid)

        if source_mode == "manufactured":
            # Apply the discrete GS stencil to the reference psi.
            # This tests solver correctness only (no truncation error).
            source_nr_nz = _compute_source_manufactured_vectorised(
                shot.psi_rz, shot.r_grid, shot.z_grid,
            )
        else:
            # Analytical Solov'ev source (tests full pipeline).
            RR_nz_nr = np.ones((nz, 1)) * shot.r_grid[np.newaxis, :]
            source_nz_nr = _compute_solovev_source(
                RR_nz_nr, shot.R0, shot.A_param, shot.scale_factor,
            )
            source_nr_nz = source_nz_nr.T

        # Run Picard+SOR forward solve
        ours = picard_sor_solve(
            r_grid=shot.r_grid,
            z_grid=shot.z_grid,
            source_2d=source_nr_nz,
            psi_boundary=shot.psi_rz,
            psi_init=None,
            max_iter=max_iter,
            omega=omega,
            tol=tol,
        )

        elapsed = time.time() - t0

        # Compare
        comparison = run_full_comparison(ours, shot)

        psi_rmse = comparison["normalized_psi_rmse"]
        axis_err_mm = comparison["axis_error"]["total_m"] * 1000.0

        if psi_rmse < 0.05:
            status = "OK"
        elif psi_rmse < 0.10:
            status = "WARN"
        else:
            status = "FAIL"

        print(
            f"[{idx + 1:2d}/{n_shots}] Shot {shot.shot_id} "
            f"({shot.category}): "
            f"psi_rmse={psi_rmse:.4f}, "
            f"axis_err={axis_err_mm:.1f}mm  "
            f"[{status}]  ({elapsed:.2f}s)"
        )

        result = {
            "shot_id": shot.shot_id,
            "category": shot.category,
            "description": shot.description,
            "R0_m": shot.R0,
            "a_m": shot.a,
            "B0_T": shot.B0,
            "Ip_MA": shot.Ip,
            "kappa": shot.kappa,
            "delta": shot.delta,
            "beta_N": shot.beta_N,
            "normalized_psi_rmse": psi_rmse,
            "axis_dr_m": comparison["axis_error"]["dr_m"],
            "axis_dz_m": comparison["axis_error"]["dz_m"],
            "axis_total_m": comparison["axis_error"]["total_m"],
            "axis_total_mm": axis_err_mm,
            "boundary_hausdorff_m": comparison["boundary_hausdorff_m"],
            "max_absolute_error": comparison["max_absolute_error"],
            "psi_range_ref": comparison["psi_range_ref"],
            "solver_converged": comparison["solver_converged"],
            "solver_iterations": comparison["solver_iterations"],
            "solver_residual": comparison["solver_residual"],
            "solve_time_s": elapsed,
            "status": status,
        }

        shot_result_path = results_dir / f"{shot.shot_id}.json"
        with open(shot_result_path, "w") as f:
            json.dump(_sanitise_for_json(result), f, indent=2)

        all_results.append(result)

    return all_results


def _sanitise_for_json(obj):
    """Recursively convert numpy types to native Python for JSON."""
    if isinstance(obj, dict):
        return {k: _sanitise_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [_sanitise_for_json(v) for v in obj]
    elif isinstance(obj, (np.integer,)):
        return int(obj)
    elif isinstance(obj, (np.floating,)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.bool_,)):
        return bool(obj)
    elif isinstance(obj, float) and np.isnan(obj):
        return None
    return obj


# =====================================================================
# Summary generation
# =====================================================================

def generate_summary_csv(results: List[dict], csv_path: Path) -> None:
    """Write summary CSV from per-shot results."""
    if not results:
        return

    fieldnames = [
        "shot_id", "category", "R0_m", "a_m", "B0_T", "Ip_MA",
        "kappa", "delta", "beta_N",
        "normalized_psi_rmse", "axis_total_mm",
        "boundary_hausdorff_m", "max_absolute_error",
        "solver_converged", "solver_iterations", "solver_residual",
        "solve_time_s", "status",
    ]

    with open(csv_path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction="ignore")
        writer.writeheader()
        for r in results:
            writer.writerow(_sanitise_for_json(r))

    print(f"\nSummary CSV written: {csv_path}")


def print_aggregate_statistics(results: List[dict]) -> None:
    """Print aggregate statistics grouped by category."""
    if not results:
        print("No results to summarise.")
        return

    categories: Dict[str, List[dict]] = {}
    for r in results:
        cat = r["category"]
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(r)

    print("\n" + "=" * 78)
    print("Forward Solve Validation Summary")
    print("=" * 78)
    print(
        f"{'Category':<25s} {'Shots':>5s} {'Mean RMSE':>10s} "
        f"{'Std RMSE':>10s} {'Max RMSE':>10s} "
        f"{'Mean Axis':>10s} {'OK/Total':>10s}"
    )
    print("-" * 78)

    total_ok = 0
    total_shots = 0

    for cat in sorted(categories.keys()):
        shots = categories[cat]
        rmses = [s["normalized_psi_rmse"] for s in shots]
        axis_errs = [s["axis_total_mm"] for s in shots]
        n_ok = sum(1 for s in shots if s["status"] == "OK")

        total_ok += n_ok
        total_shots += len(shots)

        print(
            f"{cat:<25s} {len(shots):>5d} "
            f"{float(np.mean(rmses)):>10.4f} "
            f"{float(np.std(rmses)):>10.4f} "
            f"{float(np.max(rmses)):>10.4f} "
            f"{float(np.mean(axis_errs)):>8.1f}mm "
            f"{n_ok:>4d}/{len(shots):<4d}"
        )

    print("-" * 78)

    all_rmses = [r["normalized_psi_rmse"] for r in results]
    all_axis = [r["axis_total_mm"] for r in results]
    print(
        f"{'OVERALL':<25s} {total_shots:>5d} "
        f"{float(np.mean(all_rmses)):>10.4f} "
        f"{float(np.std(all_rmses)):>10.4f} "
        f"{float(np.max(all_rmses)):>10.4f} "
        f"{float(np.mean(all_axis)):>8.1f}mm "
        f"{total_ok:>4d}/{total_shots:<4d}"
    )
    print("=" * 78)

    total_time = sum(r["solve_time_s"] for r in results)
    mean_time = total_time / len(results)
    print(f"\nTotal solve time: {total_time:.1f}s  "
          f"(mean {mean_time:.2f}s/shot)")

    n_converged = sum(1 for r in results if r["solver_converged"])
    print(f"Solver converged: {n_converged}/{total_shots}")


# =====================================================================
# CLI entry point
# =====================================================================

def main() -> None:
    """Command-line entry point."""
    parser = argparse.ArgumentParser(
        description="Forward solve validation: compare Picard+SOR GS solver "
                    "against Solov'ev analytical ground truth.",
    )
    parser.add_argument(
        "--shots-dir", type=str, default=None,
        help="Directory containing synthetic shot files. "
             "Defaults to validation/synthetic_shots/ relative to this script.",
    )
    parser.add_argument(
        "--results-dir", type=str, default=None,
        help="Directory to write results. "
             "Defaults to validation/results/forward/ relative to this script.",
    )
    parser.add_argument(
        "--max-iter", type=int, default=10000,
        help="Maximum SOR iterations (default: 10000).",
    )
    parser.add_argument(
        "--omega", type=float, default=1.7,
        help="SOR relaxation factor (default: 1.7).",
    )
    parser.add_argument(
        "--tol", type=float, default=1e-8,
        help="Convergence tolerance (default: 1e-8).",
    )
    parser.add_argument(
        "--seed", type=int, default=20260214,
        help="RNG seed for shot generation if shots don't exist (default: 20260214).",
    )
    parser.add_argument(
        "--source-mode", type=str, default="analytical",
        choices=["analytical", "manufactured"],
        help="Source term mode: 'analytical' (Solov'ev, tests full pipeline) "
             "or 'manufactured' (discrete stencil applied to reference psi, "
             "tests solver correctness only). Default: analytical.",
    )
    args = parser.parse_args()

    script_dir = Path(__file__).resolve().parent

    shots_dir = Path(args.shots_dir) if args.shots_dir else script_dir / "synthetic_shots"
    results_dir = Path(args.results_dir) if args.results_dir else script_dir / "results" / "forward"

    # Generate synthetic shots if they don't exist
    if not shots_dir.exists() or not list(shots_dir.glob("*.npz")):
        print(f"Synthetic shots not found at {shots_dir}")
        print("Generating synthetic shots...")
        print()

        import json as _json

        class _NumpyEncoder(_json.JSONEncoder):
            def default(self, obj):
                if isinstance(obj, (np.bool_,)):
                    return bool(obj)
                if isinstance(obj, (np.integer,)):
                    return int(obj)
                if isinstance(obj, (np.floating,)):
                    return float(obj)
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                return super().default(obj)

        _original_dump = _json.dump
        def _patched_dump(obj, fp, **kwargs):
            kwargs.setdefault("cls", _NumpyEncoder)
            return _original_dump(obj, fp, **kwargs)
        _json.dump = _patched_dump

        sys.path.insert(0, str(script_dir))
        from generate_synthetic_shots import generate_all_shots
        generate_all_shots(seed=args.seed, output_dir=shots_dir, save=True)

        _json.dump = _original_dump
        print()

    # Run validation
    results = run_forward_validation(
        shots_dir=shots_dir,
        results_dir=results_dir,
        max_iter=args.max_iter,
        omega=args.omega,
        tol=args.tol,
        source_mode=args.source_mode,
    )

    if not results:
        print("No results produced. Check that synthetic shots exist.")
        sys.exit(1)

    csv_path = results_dir / "summary.csv"
    generate_summary_csv(results, csv_path)
    print_aggregate_statistics(results)


if __name__ == "__main__":
    main()
