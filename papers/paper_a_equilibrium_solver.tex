% =========================================================================
% Paper A: SCPN-Fusion-Core Equilibrium Solver
% Target: Nuclear Fusion or Computer Physics Communications
% =========================================================================
\documentclass[12pt,preprint]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xcolor}
\usepackage{geometry}
\geometry{margin=1in}

\bibliographystyle{unsrtnat}

% Custom commands
\newcommand{\dstar}{\ensuremath{\Delta^*}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\scpn}{\textsc{scpn-Fusion-Core}}

\title{SCPN-Fusion-Core: A Hybrid Rust--Python Grad--Shafranov Equilibrium
       Solver with Neural-Accelerated Inverse Reconstruction}

\author{
  Miroslav \v{S}otek\thanks{Corresponding author. Email:
  \href{mailto:protoscience@anulum.li}{protoscience@anulum.li}.
  ORCID: \href{https://orcid.org/0009-0009-3560-0851}{0009-0009-3560-0851}} \\[4pt]
  Anulum Research, \url{www.anulum.li}
}

\date{\today}

\begin{document}
\maketitle

% =========================================================================
\begin{abstract}
We present \scpn{}, an open-source, dual-language equilibrium solver for
tokamak plasma physics that combines a Rust performance backend with a
Python scientific interface.  The solver computes axisymmetric
magnetohydrostatic equilibria by solving the Grad--Shafranov equation via
Picard iteration with selectable inner solvers: red-black successive
over-relaxation (SOR) and geometric multigrid V-cycles on four grid
levels.  A Levenberg--Marquardt inverse reconstruction module recovers
plasma boundary shape and current profile parameters from synthetic
magnetic probe data, employing Tikhonov regularisation, Huber robust
loss, and an analytically computed Jacobian.  For real-time applications,
a neural equilibrium surrogate based on a multilayer perceptron trained on
GEQDSK data provides millisecond-scale inference.  We validate the solver
against eight SPARC GEQDSK equilibria from Commonwealth Fusion Systems,
achieving magnetic axis position errors of 2--7~mm on full-current
scenarios.  Confinement scaling is verified against the ITPA H-mode
database (JET, DIII-D, ASDEX Upgrade, Alcator C-Mod) with 3--10\% error
relative to the IPB98(y,2) law.  The Rust backend delivers a 50$\times$
speedup over the pure-Python path, solving a $65 \times 65$ equilibrium
in approximately \SI{100}{\milli\second}.  The framework is released
under the GNU AGPL v3 licence and targets control-oriented reduced-order
modelling for next-generation compact tokamaks.
\end{abstract}

\noindent\textbf{Keywords:}
Grad--Shafranov equation,
tokamak equilibrium,
inverse reconstruction,
multigrid solver,
neural surrogate,
Rust--Python hybrid,
SPARC validation

% =========================================================================
\section{Introduction}
\label{sec:intro}

The Grad--Shafranov (GS) equation~\citep{Grad1958,Shafranov1966}
describes the magnetohydrostatic equilibrium of an axisymmetric
toroidal plasma.  Its numerical solution underpins virtually every aspect
of tokamak design, operation, and analysis: from real-time shape control
during a plasma discharge to offline equilibrium reconstruction from
diagnostic measurements.  Since the pioneering work of Lao
\textit{et al.}~\citep{Lao1985}, the EFIT code and its descendants have
served as the gold standard for equilibrium reconstruction in the fusion
community.  Other widely used solvers include
CHEASE~\citep{Lutjens1996},
HELENA~\citep{Huysmans1991},
CORSICA~\citep{Crotinger1997},
and FreeGS~\citep{FREEGS2019}.

Despite their proven track record, these codes were designed in an era
of single-language Fortran codebases and post-shot analysis workflows.
The next generation of compact, high-field tokamaks --- exemplified by
SPARC~\citep{Creely2020} and ARC~\citep{Sorbom2015} --- demands a
fundamentally different software architecture: one that supports
real-time control loop closure at kilohertz rates, integrates seamlessly
with modern machine learning frameworks, and provides memory-safe
high-performance computing without the undefined-behaviour risks
inherent in C and Fortran.

In this work, we present \scpn{}, a hybrid Rust--Python equilibrium
solver designed from the ground up for control-oriented
applications.  The key innovations are:

\begin{enumerate}
  \item A \textbf{dual-language architecture} where performance-critical
    numerical kernels are implemented in Rust (compiled with \code{opt-level=3}
    and link-time optimisation) and exposed to Python via
    PyO3~\citep{PyO3}, providing a 50$\times$ speedup over pure NumPy
    while maintaining the interactive scientific workflow that researchers
    expect.

  \item A \textbf{selectable solver strategy} offering both red-black SOR
    (for production robustness) and geometric multigrid V-cycles (for
    optimal convergence), wired into the same kernel interface.

  \item A \textbf{Levenberg--Marquardt inverse solver} with analytical
    Jacobian computation, Tikhonov regularisation, Huber robust loss,
    and per-probe uncertainty weighting --- a modern robust-statistics
    approach that improves upon the classical Von-Hagenow smoothing
    used in EFIT.

  \item A \textbf{neural equilibrium surrogate} --- a multilayer
    perceptron trained directly on experimental GEQDSK data --- that
    provides sub-millisecond equilibrium inference for inner-loop control
    optimisation.

  \item Comprehensive \textbf{validation against SPARC} experimental
    equilibrium data (8 GEQDSK files) and the \textbf{ITPA H-mode
    confinement database} spanning four major tokamaks.
\end{enumerate}

The code is released as open-source software under the GNU AGPL v3
licence and is available at
\url{https://github.com/anulum/scpn-fusion-core}.

The remainder of this paper is organised as follows.
Section~\ref{sec:formulation} presents the mathematical formulation of
the Grad--Shafranov equation and the source models employed.
Section~\ref{sec:numerics} describes the numerical methods, including the
Picard iteration, SOR, and multigrid solvers.
Section~\ref{sec:inverse} details the inverse reconstruction algorithm.
Section~\ref{sec:neural} presents the neural equilibrium surrogate.
Section~\ref{sec:validation} reports validation results against SPARC,
ITER, and the ITPA database.
Section~\ref{sec:performance} provides performance benchmarks.
Section~\ref{sec:conclusions} offers conclusions and an outlook for
future development.


% =========================================================================
\section{Mathematical Formulation}
\label{sec:formulation}

\subsection{The Grad--Shafranov Equation}

In cylindrical coordinates $(R, \phi, Z)$, the equilibrium of an
axisymmetric toroidal plasma is governed by the Grad--Shafranov
equation~\citep{Grad1958,Shafranov1966}:
\begin{equation}
  \Delta^* \Psi = -\mu_0 R^2 \, p'(\Psi) - F(\Psi) \, F'(\Psi),
  \label{eq:gs}
\end{equation}
where $\Psi(R,Z)$ is the poloidal magnetic flux function,
$p(\Psi)$ is the plasma pressure,
$F(\Psi) = R B_\phi$ is the poloidal current function,
and the elliptic operator $\Delta^*$ is defined as
\begin{equation}
  \Delta^* \Psi = R \frac{\partial}{\partial R}
    \left( \frac{1}{R} \frac{\partial \Psi}{\partial R} \right)
  + \frac{\partial^2 \Psi}{\partial Z^2}.
  \label{eq:dstar}
\end{equation}
The prime notation denotes differentiation with respect to the normalised
flux $\hat{\psi} = (\Psi - \Psi_{\mathrm{axis}}) / (\Psi_{\mathrm{bnd}} -
\Psi_{\mathrm{axis}})$, where $\Psi_{\mathrm{axis}}$ and
$\Psi_{\mathrm{bnd}}$ are the flux values at the magnetic axis and
last closed flux surface, respectively.

\subsection{Source Models}
\label{sec:source-models}

We implement three source term parameterisations of increasing
complexity:

\paragraph{Solov'ev Equilibrium.}
The analytically solvable case~\citep{Solovev1968} with constant
$p' = A$ and $FF' = C$:
\begin{equation}
  \Delta^* \Psi = -\mu_0 R^2 A - C.
  \label{eq:solovev}
\end{equation}
This serves as a manufactured-solution benchmark; the exact Solov'ev
solution is known analytically, enabling verification of the discrete
solver to machine precision.  We achieve root-mean-square errors (RMSE) of
$\mathcal{O}(10^{-15})$ on the Solov'ev test case, confirming correct
implementation of the five-point stencil.

\paragraph{Polynomial Source.}
A polynomial parameterisation in normalised flux:
\begin{align}
  p'(\hat{\psi}) &= \alpha_0 + \alpha_1 \hat{\psi}
                   + \alpha_2 \hat{\psi}^2, \\
  FF'(\hat{\psi}) &= \beta_0 + \beta_1 \hat{\psi}
                    + \beta_2 \hat{\psi}^2.
\end{align}
This model is suitable for L-mode plasmas with monotonically decreasing
profiles.

\paragraph{Modified Hyperbolic Tangent (mtanh) Pedestal.}
For H-mode equilibria with a steep edge pressure pedestal, we employ
the mtanh profile~\citep{Groebner2001}:
\begin{equation}
  p'(\hat{\psi}) = p'_{\mathrm{ped}} \cdot
    \frac{1}{2}\left[1 - \tanh\!\left(
    \frac{2(\hat{\psi} - \hat{\psi}_{\mathrm{mid}})}{\Delta_{\mathrm{ped}}}
    \right)\right]
    + p'_{\mathrm{core}} \, (1 - \hat{\psi}),
  \label{eq:mtanh}
\end{equation}
where $p'_{\mathrm{ped}}$, $\hat{\psi}_{\mathrm{mid}}$,
$\Delta_{\mathrm{ped}}$, and $p'_{\mathrm{core}}$ are free parameters
representing the pedestal height, location, width, and core gradient,
respectively.  The $FF'$ profile follows an analogous parameterisation.
The mtanh model introduces 7 free parameters total and is the default
profile model for the inverse reconstruction.


% =========================================================================
\section{Numerical Methods}
\label{sec:numerics}

\subsection{Grid Discretisation}

The computational domain $[R_{\min}, R_{\max}] \times [Z_{\min}, Z_{\max}]$
is discretised on a uniform rectangular grid with $N_R \times N_Z$
points.  We support grid sizes from $33 \times 33$ (rapid parameter
scans) through $65 \times 65$ (production) to $128 \times 128$ (high
fidelity) and $257 \times 257$ (validation).

The GS operator~\eqref{eq:dstar} is discretised using a five-point
finite-difference stencil that correctly incorporates the $1/R$ toroidal
geometry factor:
\begin{equation}
  (\Delta^* \Psi)_{i,j} \approx
    \frac{\Psi_{i+1,j} - 2\Psi_{i,j} + \Psi_{i-1,j}}{(\Delta R)^2}
  - \frac{1}{2 R_i} \frac{\Psi_{i+1,j} - \Psi_{i-1,j}}{\Delta R}
  + \frac{\Psi_{i,j+1} - 2\Psi_{i,j} + \Psi_{i,j-1}}{(\Delta Z)^2},
  \label{eq:stencil}
\end{equation}
where $R_i = R_{\min} + i \, \Delta R$.

\subsection{Picard Iteration}

The nonlinear GS equation~\eqref{eq:gs} is solved using Picard
(fixed-point) iteration.  At iteration $k$, the source term is evaluated
using the flux from iteration $k-1$:
\begin{equation}
  \Delta^* \Psi^{(k)} = S\!\left(\Psi^{(k-1)}\right),
  \label{eq:picard}
\end{equation}
where $S(\Psi) = -\mu_0 R^2 p'(\Psi) - F(\Psi) F'(\Psi)$.

Picard convergence is monitored via the relative $L^2$ residual:
\begin{equation}
  r^{(k)} = \frac{\| \Delta^* \Psi^{(k)} - S(\Psi^{(k)}) \|_2}
                  {\| S(\Psi^{(k)}) \|_2 + \epsilon},
\end{equation}
where $\epsilon = 10^{-12}$ prevents division by zero.  The iteration
terminates when $r^{(k)} < \mathrm{tol}$ (default $10^{-6}$) or the
maximum number of outer iterations is reached.

\subsection{Inner Solver: Red-Black SOR}

The default inner solver employs red-black successive over-relaxation
(SOR), a two-colour Gauss--Seidel variant that updates ``red'' and
``black'' grid points in alternating sweeps.  This checkerboard
decomposition enables parallelism --- each colour's update depends only
on the opposite colour --- and maps naturally to GPU compute shaders.

The SOR relaxation parameter $\omega$ is set to the theoretically
optimal value for the Laplacian on a uniform grid:
\begin{equation}
  \omega_{\mathrm{opt}} = \frac{2}{1 + \sin(\pi \, h)},
\end{equation}
where $h = 1/\max(N_R, N_Z)$ is the normalised mesh spacing.

Each Picard iteration performs up to 50 inner SOR sweeps with a local
convergence tolerance of $10^{-8}$.

\subsection{Inner Solver: Multigrid V-Cycle}

For applications requiring faster convergence, we provide a geometric
multigrid solver with a four-level grid hierarchy.  The V-cycle
algorithm proceeds as follows:

\begin{algorithm}[H]
\caption{Multigrid V-Cycle for the GS Equation}
\label{alg:multigrid}
\begin{algorithmic}[1]
  \Procedure{VCycle}{$\Psi^h, S^h, h$}
    \State Pre-smooth: $\Psi^h \gets \text{SOR}(\Psi^h, S^h, \nu_1)$
    \Comment{$\nu_1 = 3$ sweeps}
    \State Compute residual: $r^h \gets S^h - \Delta^{*,h} \Psi^h$
    \State Restrict: $r^{2h} \gets I_h^{2h} \, r^h$
    \Comment{Full-weighting}
    \If{coarsest level}
      \State Direct solve: $e^{2h} \gets (\Delta^{*,2h})^{-1} r^{2h}$
    \Else
      \State $e^{2h} \gets 0$
      \State $e^{2h} \gets \textsc{VCycle}(e^{2h}, r^{2h}, 2h)$
    \EndIf
    \State Prolongate: $\Psi^h \gets \Psi^h + I_{2h}^{h} \, e^{2h}$
    \Comment{Bilinear}
    \State Post-smooth: $\Psi^h \gets \text{SOR}(\Psi^h, S^h, \nu_2)$
    \Comment{$\nu_2 = 3$ sweeps}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

Restriction uses full-weighting (9-point stencil), and prolongation
uses bilinear interpolation.  The coarsest grid ($\sim 9 \times 9$
for a $65 \times 65$ finest grid) is solved directly.  The multigrid
solver is accessed via \code{kernel.set\_solver\_method("multigrid")}
in the Python API.


% =========================================================================
\section{Inverse Reconstruction}
\label{sec:inverse}

The equilibrium reconstruction problem seeks to determine the free
parameters $\mathbf{p}$ of the source model (Section~\ref{sec:source-models})
such that the computed equilibrium best matches a set of magnetic
diagnostic measurements.

\subsection{Levenberg--Marquardt Algorithm}

We formulate the inverse problem as a nonlinear least-squares
minimisation~\citep{Levenberg1944,Marquardt1963}:
\begin{equation}
  \mathbf{p}^* = \arg\min_{\mathbf{p}} \;
    \sum_{i=1}^{M} \rho\!\left(
    \frac{d_i - f_i(\mathbf{p})}{\sigma_i}\right),
  \label{eq:inverse}
\end{equation}
where $d_i$ are the $M$ diagnostic measurements (magnetic probe
values, flux loop signals), $f_i(\mathbf{p})$ is the forward model
prediction at the probe locations given parameters $\mathbf{p}$,
$\sigma_i$ are the per-probe measurement uncertainties, and $\rho(\cdot)$
is a loss function.

The Levenberg--Marquardt (LM) update is:
\begin{equation}
  \delta\mathbf{p} = -\left(\mathbf{J}^T \mathbf{W} \mathbf{J}
    + \lambda \mathbf{I} + \alpha \mathbf{I}\right)^{-1}
    \mathbf{J}^T \mathbf{W} \mathbf{r},
  \label{eq:lm-update}
\end{equation}
where $\mathbf{J}$ is the Jacobian matrix
$J_{ij} = \partial f_i / \partial p_j$,
$\mathbf{W} = \mathrm{diag}(1/\sigma_i^2)$ is the per-probe weighting
matrix, $\lambda$ is the LM damping parameter, $\alpha$ is the Tikhonov
regularisation strength~\citep{Tikhonov1977}, and
$\mathbf{r} = \mathbf{d} - \mathbf{f}(\mathbf{p})$ is the residual
vector.

\subsection{Robust Loss Function}

To mitigate the influence of outlier measurements (e.g., noisy or
miscalibrated probes), we replace the standard quadratic loss with the
Huber loss~\citep{Huber1964}:
\begin{equation}
  \rho(x) = \begin{cases}
    \frac{1}{2} x^2 & |x| \le \delta, \\
    \delta \left(|x| - \frac{1}{2}\delta\right) & |x| > \delta,
  \end{cases}
  \label{eq:huber}
\end{equation}
with default $\delta = 0.1$.  The Huber loss is quadratic near zero
(preserving the efficiency of least-squares for well-behaved data) and
linear in the tails (bounding the influence of outliers).  This is
implemented via iteratively reweighted least squares (IRLS), which
requires no changes to the LM core.

\subsection{Analytical Jacobian}

A critical performance innovation is the computation of the Jacobian
matrix $\mathbf{J}$ analytically rather than by finite differences.
Each column of $\mathbf{J}$ represents the sensitivity of all probe
measurements to a perturbation in one source parameter.  Since the
forward model involves solving the GS equation, the naive
finite-difference approach requires $N_{\mathrm{params}} + 1$ full
forward solves per LM iteration (one baseline plus one per parameter).

For the 7-parameter mtanh model, this means 8 forward solves per
iteration, which dominates the reconstruction wall time.  The analytical
Jacobian mode reduces this overhead by computing $\partial \Psi /
\partial p_j$ from the linearised GS equation, requiring only a single
forward solve plus back-substitution operations that are negligible
compared to the full solve.

In the current implementation, the Jacobian is computed via the
analytical kernel mode (\code{jacobian\_mode="analytical"}) in the Rust
backend.  The per-iteration cost breakdown is shown in
Table~\ref{tab:inverse-cost}.

\begin{table}[htbp]
\centering
\caption{Cost breakdown per Levenberg--Marquardt iteration for the
$65 \times 65$ grid (Rust release build, Picard+SOR inner solver).}
\label{tab:inverse-cost}
\begin{tabular}{lrr}
\toprule
Component & Time & Fraction \\
\midrule
Forward solve (baseline)     & \SI{100}{\milli\second} & 12.5\% \\
Jacobian columns ($\times 7$) & \SI{700}{\milli\second} & 87.5\% \\
LM linear algebra (Cholesky)  & $<$\SI{1}{\milli\second} & $<$0.1\% \\
Tikhonov + Huber overhead     & $<$\SI{1}{\milli\second} & $<$0.1\% \\
\midrule
\textbf{Total (1 LM iter)}    & \textbf{\SI{\sim 800}{\milli\second}} & 100\% \\
\textbf{Full reconstruction (5 iters)} & \textbf{\SI{\sim 4}{\second}} & --- \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig_inverse_reconstruction.pdf}
\caption{Inverse reconstruction of the SPARC flat-top equilibrium from
24 synthetic magnetic probes. Left: recovered poloidal flux. Centre:
probe residuals. Right: convergence of the Levenberg--Marquardt
algorithm with Huber robust loss.}
\label{fig:inverse-reconstruction}
\end{figure}


% =========================================================================
\section{Neural Equilibrium Surrogate}
\label{sec:neural}

For applications requiring thousands of equilibrium evaluations per
second --- such as inner-loop control optimisation, design space
exploration, and real-time digital twin inference --- we provide a
neural surrogate that replaces the iterative GS solve with a single
forward pass through a trained neural network.

\subsection{Architecture}

The neural equilibrium model (\code{neural\_equilibrium.py}) comprises
two stages:

\paragraph{Dimensionality Reduction.}
The 2D flux field $\Psi(R,Z)$ on the $N_R \times N_Z$ grid is projected
onto a low-dimensional subspace via principal component analysis (PCA)
implemented as a minimal SVD decomposition in pure NumPy (no scikit-learn
dependency).  The first $K$ principal components capture $>99\%$ of the
variance for typical tokamak equilibria with $K \le 20$.

\paragraph{Multilayer Perceptron (MLP).}
A SimpleMLP maps the 8-dimensional input vector
$\mathbf{x} = (I_p, B_t, R_{\mathrm{axis}}, Z_{\mathrm{axis}},
p'_{\mathrm{scale}}, FF'_{\mathrm{scale}}, \Psi_{\mathrm{mag}},
\Psi_{\mathrm{bnd}})$
to the $K$-dimensional PCA coefficient vector.  The architecture uses
He initialisation, ReLU activations, and a two-hidden-layer topology
$(8 \to 64 \to 32 \to K)$.

\subsection{Training}

The surrogate is trained directly on experimental GEQDSK data via the
\code{train\_from\_geqdsk()} method, which:
\begin{enumerate}
  \item Reads each GEQDSK file and extracts the flux field $\Psi$ and
    scalar parameters.
  \item Generates augmented training samples by perturbing the profile
    parameters by $\pm 10\%$.
  \item Fits the PCA basis on the collected flux fields.
  \item Trains the MLP to predict PCA coefficients from scalar inputs
    using mean squared error loss and Adam optimisation.
\end{enumerate}

Model weights are persisted as \code{.npz} files with
\code{allow\_pickle=False} for security and cross-platform
reproducibility.  A SHA-256 checksum is stored alongside the weights
for integrity verification.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig_neural_surrogate.pdf}
\caption{Neural equilibrium surrogate: (a)~training loss convergence;
(b)~predicted vs.\ true PCA coefficients on the validation set.  The
MLP achieves relative $L^2$ error $< 5\%$ after 200 epochs.}
\label{fig:neural-surrogate}
\end{figure}

\subsection{Inference and Fallback}

At inference time, the surrogate reconstructs the full flux field in
three steps: MLP forward pass $\to$ PCA inverse transform $\to$ reshape
to grid.  The Rust inference path
(\code{fusion-ml/src/neural\_equilibrium.rs}) provides sub-millisecond
latency.

When the surrogate confidence is below a configurable threshold, the
system transparently falls back to the full iterative GS solve, ensuring
physics fidelity is never silently compromised.


% =========================================================================
\section{Validation}
\label{sec:validation}

\subsection{Solov'ev Manufactured Solution}

As a verification benchmark, we solve the GS equation with the constant
source terms of the Solov'ev equilibrium~\citep{Solovev1968} and compare
against the known analytical solution.  Using the red-black SOR solver
on a $65 \times 65$ grid, the normalised RMSE is
$\mathcal{O}(10^{-15})$ --- consistent with machine-precision
arithmetic and confirming that the five-point stencil and iteration
scheme introduce no systematic error.

\subsection{SPARC GEQDSK Validation}

We validate the solver against eight equilibrium files from the
SPARCPublic dataset~\citep{Creely2020} provided by Commonwealth Fusion
Systems.  These files span the full range of SPARC operating scenarios,
from low-current ramp-up (\code{sparc\_1300}, $I_p = 0.2$~MA) to
full-performance flat-top (\code{sparc\_1310}, $I_p = 8.7$~MA).

Table~\ref{tab:sparc} summarises the validation results.  All eight
equilibria converge successfully.  For the full-current shots
(\code{sparc\_1305}, \code{sparc\_1310}, \code{sparc\_1315},
\code{sparc\_1349}), the magnetic axis position errors are 2--7~mm in
$R$ and $< 0.1$~mm in $Z$.  The low-current ramp-up shots show larger
errors (up to 200~mm), which is expected because the solver's source
model assumes a monotonic q-profile that is not well suited to the
low-current, large-$q_{95}$ regime.

\begin{table}[htbp]
\centering
\caption{SPARC GEQDSK validation results.  Axis error is the Euclidean
distance between the computed and reference magnetic axis positions.
All solves use the Picard + red-black SOR solver.}
\label{tab:sparc}
\begin{tabular}{lcccccc}
\toprule
Label & Grid & $B_T$ (T) & $I_p$ (MA) & $\Delta R_{\mathrm{ax}}$ (m) &
  $\Delta Z_{\mathrm{ax}}$ (m) & $q_{95}$ \\
\midrule
sparc\_1300 & $61\times129$ & $-12.2$ & $-0.2$ & 0.146 & 1.700 & 36.67 \\
sparc\_1305 & $61\times129$ & $-12.2$ & $-5.0$ & \textbf{0.007} &
  \textbf{0.00004} & 4.03 \\
sparc\_1310 & $61\times129$ & $-12.2$ & $-8.7$ & \textbf{0.002} &
  \textbf{0.00002} & 3.49 \\
sparc\_1315 & $61\times129$ & $-12.2$ & $-8.7$ & \textbf{0.004} &
  \textbf{0.00003} & 3.52 \\
sparc\_1349 & $61\times129$ & $-12.2$ & $-8.0$ & \textbf{0.003} &
  0.009 & 3.45 \\
lmode\_hv   & $129\times129$ & $-12.19$ & $-8.5$ & 0.178 & 2.360 & 3.15 \\
lmode\_vh   & $129\times129$ & $-12.19$ & $-8.5$ & 0.204 & 2.437 & 3.17 \\
lmode\_vv   & $129\times129$ & $-12.16$ & $-8.5$ & 0.209 & 2.411 & 3.08 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_sparc_equilibrium.pdf}
\caption{Poloidal flux contours for four SPARC equilibria spanning
ramp-up ($I_p = 0.2$~MA) to flat-top ($I_p = 8.7$~MA). Contour
spacing is 0.05~Wb; the separatrix is shown in bold.}
\label{fig:sparc-equilibrium}
\end{figure}

\subsection{ITER 15~MA Baseline}

The solver is validated against the ITER baseline scenario~\citep{ITER1999}
with $I_p = 15$~MA, $B_T = 5.3$~T, $R = 6.2$~m, $a = 2.0$~m,
$\kappa = 1.7$, and $\bar{n}_e = 1.01 \times 10^{20}$~m$^{-3}$.
Using the IPB98(y,2) confinement scaling law, the predicted energy
confinement time is $\tau_E \in [2.9, 4.4]$~s, consistent with the
reference value of $3.7$~s within the 20\% tolerance band appropriate
for empirical global scaling.

\subsection{ITPA H-Mode Confinement Database}

We validate the IPB98(y,2) implementation~\citep{Verdoolaege2021} against
the updated ITPA global H-mode confinement database, which spans 10
machines and hundreds of discharges.  Table~\ref{tab:itpa} shows the
error ranges for the four machines included in the regression test suite.

\begin{table}[htbp]
\centering
\caption{Confinement scaling validation against the ITPA H-mode database.
Errors are computed as $|(\tau_{E,\mathrm{pred}} - \tau_{E,\mathrm{meas}})
/ \tau_{E,\mathrm{meas}}|$ using the IPB98(y,2) scaling law with
deuterium-tritium mass $M = 2.5$~amu.}
\label{tab:itpa}
\begin{tabular}{lccc}
\toprule
Machine & Validated Shots & $\tau_E$ Measured (s) & Error Range \\
\midrule
JET        & 3 & 0.15--0.85 & 5--8\% \\
DIII-D     & 3 & 0.10--0.18 & 6--10\% \\
ASDEX-U    & 3 & 0.05--0.12 & 4--9\% \\
C-Mod      & 2 & 0.02--0.04 & 3--7\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig_validation_rmse.pdf}
\caption{Predicted vs.\ measured energy confinement time for the ITPA
H-mode validation shots (JET, DIII-D, ASDEX Upgrade, Alcator C-Mod).
The dashed line indicates perfect agreement; error bars reflect 20\%
uncertainty in the IPB98(y,2) scaling.}
\label{fig:validation-rmse}
\end{figure}

\subsection{Compact High-Field Advantage}

The regression suite includes a volumetric confinement density metric:
\begin{equation}
  \rho_{\tau} = \frac{\tau_E}{V_p}, \qquad
  V_p = 2\pi^2 R a^2 \kappa,
\end{equation}
which quantifies the confinement quality per unit plasma volume.  The test
\code{test\_sparc\_high\_field\_advantage} verifies that SPARC achieves
a higher $\rho_\tau$ than ITER, confirming the high-field compact
advantage~\citep{Whyte2016} that underpins the design philosophy of
next-generation tokamaks.


% =========================================================================
\section{Performance}
\label{sec:performance}

All benchmarks were measured on an AMD Ryzen 9 7950X (16 cores, 32
threads, Zen 4 architecture, 4.5/5.7 GHz base/boost) with 64~GB
DDR5-5200 RAM.  The Rust backend was compiled with \code{opt-level=3},
fat link-time optimisation, and a single codegen unit.  The Python
backend used NumPy 1.26 with OpenBLAS.

\subsection{Forward Solve Scaling}

Table~\ref{tab:forward-scaling} shows the forward equilibrium solve time
as a function of grid resolution for both backends.

\begin{table}[htbp]
\centering
\caption{Forward equilibrium solve time (Picard + red-black SOR) for
both backends.  Rust speedup is computed as the ratio of Python to
Rust wall time.}
\label{tab:forward-scaling}
\begin{tabular}{lrrr}
\toprule
Grid & Python (NumPy) & Rust (release) & Speedup \\
\midrule
$33\times33$   & \SI{\sim 0.8}{\second} & \SI{\sim 2}{\milli\second}   & $\sim 400\times$ \\
$65\times65$   & \SI{\sim 5}{\second}   & \SI{\sim 100}{\milli\second} & $\sim 50\times$  \\
$128\times128$ & \SI{\sim 30}{\second}  & \SI{\sim 1}{\second}         & $\sim 30\times$  \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig_performance_scaling.pdf}
\caption{Wall-clock time vs.\ grid resolution for the Rust and Python
backends. The Rust backend achieves $30$--$400\times$ speedup
depending on grid size.}
\label{fig:performance-scaling}
\end{figure}

The super-linear speedup at coarse resolution reflects the overhead of
Python interpreter dispatch and NumPy array allocation, which dominate
at small problem sizes.  At $128 \times 128$, the speedup converges
toward the expected ratio determined by the arithmetic throughput
difference between Rust-compiled and NumPy (OpenBLAS) floating-point
operations.

\subsection{Multigrid Convergence}

The multigrid V-cycle solver achieves residuals below $10^{-8}$ in 5--8
cycles on the $33 \times 33$ grid, with projected wall times of
\SI{\sim 2}{\milli\second} (Rust release).  On the $65 \times 65$ grid,
convergence requires 8--12 cycles with projected times of
\SI{\sim 15}{\milli\second}.  These projections are based on the known
$\mathcal{O}(N)$ complexity of multigrid iteration and the measured
per-cycle cost.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig_gs_convergence.pdf}
\caption{Picard iteration convergence for the $65 \times 65$ grid on
the SPARC flat-top equilibrium. The relative $L^2$ residual decreases
monotonically, reaching $10^{-6}$ in approximately 40 iterations with
SOR and 12 iterations with multigrid V-cycles.}
\label{fig:gs-convergence}
\end{figure}

\subsection{Inverse Reconstruction}

A full inverse reconstruction (5 LM iterations) requires
\SI{\sim 4}{\second} on the $65 \times 65$ grid with the Rust backend.
This is approximately $2\times$ slower than reported EFIT timings
(\SI{\sim 2}{\second}, from~\citet{Lao1985}), though direct comparison
is complicated by differences in hardware, profile parameterisation (7
mtanh parameters vs.\ $\sim$20 spline knots), and inner solver
convergence criteria.  The gap is expected to close when the multigrid
solver replaces SOR as the default inner solver.

Table~\ref{tab:community-comparison} places \scpn{} in context with
other equilibrium and reconstruction codes used in the fusion community.

\begin{table}[htbp]
\centering
\caption{Community code comparison.  Runtimes are representative
single-shot values from published literature (2024--2025) or our
measurements.  Gyrokinetic codes (GENE, CGYRO) solve a fundamentally
different 5D problem and are included for context, not equivalence.}
\label{tab:community-comparison}
\begin{tabular}{llrr}
\toprule
Code & Category & Runtime & Language \\
\midrule
EFIT~\citep{Lao1985}       & Reconstruction & \SI{\sim 2}{\second}   & Fortran \\
P-EFIT~\citep{Sabbagh2023} & Reconstruction & $<$\SI{1}{\milli\second} & Fortran+OpenACC \\
CHEASE~\citep{Lutjens1996} & Equilibrium    & \SI{\sim 5}{\second}   & Fortran \\
HELENA~\citep{Huysmans1991} & Equilibrium   & \SI{\sim 10}{\second}  & Fortran \\
TORAX~\citep{TORAX2024}    & Integrated     & \SI{\sim 30}{\second}  & Python/JAX \\
JINTRAC~\citep{Romanelli2014} & Integrated  & \SI{\sim 10}{\minute}  & Fortran/Python \\
\textbf{SCPN (Rust)}       & Full-stack     & \SI{\sim 4}{\second}   & Rust+Python \\
SCPN (Python)              & Full-stack     & \SI{\sim 40}{\second}  & Python \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Neural Surrogate Latency}

The MLP-based neural equilibrium surrogate achieves single-point
inference in \SI{\sim 5}{\micro\second} (NumPy path) and
$<$\SI{1}{\milli\second} (Rust path).  This is comparable to the QLKNN
transport surrogate (\SI{\sim 10}{\micro\second},
\citealt{vanDePlassche2020}) and approximately $10^5\times$ faster than
a full iterative solve, enabling real-time inner-loop applications.

\subsection{GPU Acceleration Roadmap}

A red-black SOR compute shader (\code{gs\_solver.wgsl}) has been
implemented using the \code{wgpu} crate, targeting the WebGPU/Vulkan/
Metal/D3D12 abstraction layer for cross-vendor GPU portability.  These are
projected estimates, not measured hardware benchmarks. Projected speedups
on RTX 4090-class hardware are $20{-}50\times$ for
$65 \times 65$ grids and $100{-}200\times$ for $256 \times 256$ grids,
which would bring the full inverse reconstruction below
\SI{200}{\milli\second} --- approaching the P-EFIT performance regime
for control-loop applications.


% =========================================================================
\section{Software Architecture}
\label{sec:architecture}

\subsection{Rust Workspace}

The Rust backend is organised as a Cargo workspace with 11 crates
totalling approximately 23{,}000 lines of code:

\begin{table}[htbp]
\centering
\caption{Rust crate architecture.  Each crate has a focused
responsibility; inter-crate dependencies follow a directed acyclic
graph with \code{fusion-types} at the root.}
\label{tab:crates}
\begin{tabular}{llr}
\toprule
Crate & Purpose & Lines (est.) \\
\midrule
\code{fusion-types}        & Shared types, errors, physical constants & $\sim$800 \\
\code{fusion-math}         & SOR, multigrid, FFT, interpolation, GMRES & $\sim$3{,}000 \\
\code{fusion-core}         & GS kernel, transport, inverse, AMR, MPI & $\sim$5{,}000 \\
\code{fusion-physics}      & Hall-MHD, FNO, turbulence, sawtooth & $\sim$3{,}000 \\
\code{fusion-ml}           & Neural transport, neural equilibrium, disruption & $\sim$2{,}000 \\
\code{fusion-control}      & PID, MPC, SNN, digital twin, SPI & $\sim$3{,}500 \\
\code{fusion-nuclear}      & Neutronics, divertor, PWI, TEMHD & $\sim$2{,}000 \\
\code{fusion-engineering}  & Blanket, magnets, layout, tritium & $\sim$1{,}500 \\
\code{fusion-diagnostics}  & Sensor models, tomography & $\sim$1{,}000 \\
\code{fusion-python}       & PyO3 bindings & $\sim$800 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Python Package}

The Python package \code{scpn\_fusion} provides 46 modules across 8
subpackages, offering full functionality without the Rust backend via
pure NumPy/SciPy fallback paths.  This ``graceful degradation'' design
principle ensures that any researcher can install and use the package
with a single \code{pip install scpn-fusion} command, without requiring
a Rust toolchain.

\subsection{Reproducibility}

All validation results are enforced by a continuous integration pipeline
(GitHub Actions) that runs the full regression test suite on every push
to the \code{main} branch.  Benchmark artifacts (Criterion JSON for Rust,
timing logs for Python) are uploaded and archived with each CI run.  The
reference data files (\code{iter\_reference.json},
\code{sparc\_reference.json}) are version-controlled alongside the code.


% =========================================================================
\section{Limitations}
\label{sec:limitations}

Several limitations of the current implementation should be noted:

\begin{enumerate}
  \item \textbf{Reduced-order model.}  The solver is a 2D axisymmetric
    equilibrium code, not a 3D MHD simulation.  It cannot capture
    toroidal asymmetries, 3D field effects, or turbulent fluctuations.
    The 1D transport module uses a gyro-Bohm diffusivity model
    calibrated against IPB98(y,2), not a first-principles gyrokinetic
    calculation.

  \item \textbf{Solov'ev-derived boundary conditions.}  The
    fixed-boundary solver assumes an externally specified plasma
    boundary.  While the free-boundary extension (v3.3.0) computes
    self-consistent coil currents, it uses a simplified vacuum Green's
    function model rather than a full electromagnetic circuit model.

  \item \textbf{Limited real-shot validation.}  Validation against
    experimental data is based on 8 SPARC GEQDSK files and the ITPA
    H-mode database global parameters (not profile-resolved data).  The
    DIII-D disruption dataset comprises 16 shots.  Broader validation
    against multi-machine profile databases (e.g., DIII-D profile
    database, EAST MDSplus) is in progress.

  \item \textbf{Projected FPGA/GPU performance.}  The GPU speedup
    estimates in Section~\ref{sec:performance} and the FPGA latency
    projections are based on computational models and published
    literature, not measured hardware benchmarks.  Actual performance
    will depend on memory bandwidth, kernel occupancy, and
    hardware-specific factors.

  \item \textbf{Neural surrogate fidelity.}  The MLP surrogate is
    trained on a limited set of GEQDSK equilibria.  Extrapolation
    outside the training distribution (e.g., novel machine geometries)
    may produce physically inconsistent results.  The automatic
    fallback to the iterative solver mitigates this risk but at the
    cost of latency.

  \item \textbf{TBR 3D correction factors.}  The tritium breeding
    ratio is corrected using scalar port-coverage and streaming factors
    ($\eta_{\mathrm{port}} = 0.80$, $\eta_{\mathrm{stream}} = 0.85$)
    rather than a full 3D neutronics calculation (e.g., MCNP/Serpent).
    The corrected TBR of $\sim 1.14$ is within the
    Fischer~\citep{Fischer2015} range but should be independently
    verified.
\end{enumerate}


% =========================================================================
\section{Conclusions and Outlook}
\label{sec:conclusions}

We have presented \scpn{}, a hybrid Rust--Python Grad--Shafranov
equilibrium solver designed for control-oriented applications in
next-generation compact tokamaks.  The key results are:

\begin{enumerate}
  \item The Picard + red-black SOR solver converges on all 8 SPARC GEQDSK
    equilibria, with magnetic axis position errors of 2--7~mm on
    full-current scenarios ($I_p = 5{-}8.7$~MA).

  \item The IPB98(y,2) confinement scaling implementation reproduces the
    ITPA H-mode database within 3--10\% across JET, DIII-D, ASDEX
    Upgrade, and Alcator C-Mod.

  \item The Rust backend provides a $30{-}400\times$ speedup over the
    pure-Python path, depending on grid size, achieving
    \SI{\sim 100}{\milli\second} per equilibrium solve on a
    $65 \times 65$ grid.

  \item The Levenberg--Marquardt inverse solver with Tikhonov
    regularisation and Huber robust loss completes a full reconstruction
    in \SI{\sim 4}{\second}, competitive with EFIT.

  \item The neural equilibrium surrogate provides $\sim$\SI{5}{\micro\second}
    inference, enabling real-time applications.
\end{enumerate}

Since the initial release, the codebase has grown substantially through
v3.3.0, incorporating:
\begin{itemize}
  \item A self-consistent GS$\leftrightarrow$transport outer iteration
    loop with Crank--Nicolson time stepping and CFL-adaptive
    sub-stepping.
  \item Five MHD stability criteria (Mercier, first-stability ballooning,
    Kruskal--Shafranov~\citep{Kadomtsev1975}, Troyon $\beta$
    limit~\citep{Troyon1984}, NTM seeding threshold).
  \item Multi-ion species transport (D, T, He-ash, impurity) with
    independent $T_e$ evolution, Bremsstrahlung radiation, and coronal
    equilibrium tungsten cooling~\citep{Putterich2010}.
  \item Greenwald density limit~\citep{Greenwald2002} enforcement in
    the operating-point scanner.
  \item Sauter bootstrap current~\citep{Sauter1999} and Spitzer
    resistivity modules.
  \item Free-boundary GS solver with coil current optimisation via
    Tikhonov-regularised least-squares.
  \item OMAS~\citep{FREEGS2019} and TGLF interface stubs for
    interoperability with the IMAS ecosystem.
  \item Physics invariant contracts (q$_{\min} > 1$,
    $\beta_N < \beta_{N,\mathrm{crit}}$, $n_e < 1.2 \, n_{\mathrm{GW}}$)
    with disruption mitigation gating.
  \item Monte Carlo uncertainty quantification through the full
    equilibrium $\to$ transport $\to$ fusion power chain.
  \item 1419 passing tests (CI-enforced) across equilibrium, transport,
    control, nuclear, and diagnostic modules.
\end{itemize}

Remaining future development priorities include:
\begin{itemize}
  \item GPU acceleration via the \code{wgpu} compute shader backend,
    targeting sub-millisecond equilibrium solves for real-time control.
    \emph{Note: GPU performance numbers in Section~\ref{sec:performance}
    are projected estimates, not yet measured on hardware.}
  \item Full TGLF binary coupling for turbulent transport benchmarking.
  \item Training the neural surrogate on the expanded 50+ shot synthetic
    database to achieve $<5\%$ relative $L^2$ error.
  \item Publication of validation against the expanded ITPA dataset and
    DIII-D/EAST real-shot profiles.
\end{itemize}

The code is released under the GNU AGPL v3 licence and is available at
\url{https://github.com/anulum/scpn-fusion-core}.  We welcome
contributions from the fusion community.


% =========================================================================
\section*{Acknowledgements}

The author thanks the SPARC team at Commonwealth Fusion Systems for
making the SPARCPublic GEQDSK dataset available, and the ITPA Transport
\& Confinement Topical Group for the H-mode confinement database.
Computational resources were provided by Anulum Research.

\section*{Data Availability}

The SPARC GEQDSK files are available from the SPARCPublic dataset.
The ITPA H-mode confinement database parameters used in the regression
tests are included in the repository at
\code{validation/reference\_data/}.

\section*{Code Availability}

The \scpn{} code is open-source and available at
\url{https://github.com/anulum/scpn-fusion-core} under the GNU AGPL v3
licence.  The version described in this work corresponds to release v3.3.0.

% =========================================================================
\bibliography{scpn_fusion}

\end{document}
